{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"dranspose","text":"<p>Dranspose introduces a novel approach to experimental feedback by enabling direct intervention during scanning.  Rather than waiting for a scan to complete, this software allows real-time interruption of suboptimal scans,  enhancing efficiency and reducing the likelihood of processing flawed data.  Dranspose's capability to intervene during scanning represents a valuable tool for researchers seeking immediate control over experimental outcomes,  promoting a more agile and adaptive research process.</p>"},{"location":"#getting-started","title":"Getting started","text":"<p>The easiest way to test dranspose is to install the python package</p> <pre><code>pip install dranspose\n</code></pre> <p>To get a feel of building an analysis, please follow the tutorial.</p>"},{"location":"#conda","title":"Conda","text":"<p>Dranspose is also available on conda-forge and is installed with</p> <pre><code> conda install conda-forge::dranspose\n</code></pre>"},{"location":"#cli","title":"CLI","text":"<p>The packet provides a cli <code>dranspose</code> to run the components separately or all combined.  To run the full distributed system, a <code>redis</code> server is required. A convenient way is to use the docker image</p> <p>NOBUGS 2024</p> <p>There is a conference talk with a new overview and performance measurements.</p> <p>Slides</p> <p>Presentation</p> <p>There is a seminar talk with a general overview available. Some details might be out of date.</p> <p>Slides</p> <p>Poster</p> <p>There is a poster with developer information.</p> <p>Poster</p>"},{"location":"#applications","title":"Applications","text":"<p>If you are looking for help with developing an application on top of dranspose, have a look at the application section</p>"},{"location":"#example-payloads","title":"Example Payloads","text":"<p>There are some examples of analysis payloads available for beamlines at Max IV. They provide an overview of possible live calculations possible with dranspose.</p>"},{"location":"applications/hdf5_stream/","title":"Developing an Analysis from HDF5 Data","text":"<p>Sometimes, recording the data to develop an analysis in advance is not feasible. The replay module of dranspose usually reads from recorded data via cbors files.</p> <p>However, it is possible to provide custom streams instead of cbors. Special attention needs to be provided to create a stream which is similar to the one encounted at the experiment.</p> <p>Instead of providing the <code>-f</code> parameter to replay, use <code>--source</code> or <code>-s</code> to provide a python class path, e.g.:</p> <pre><code>dranspose replay -w \"src.worker:FluorescenceWorker\" -r \"src.reducer:FluorescenceReducer\" -s \"src.hdf5_sources:FluorescenceSource\" -p params.json\n</code></pre> <p>The <code>FluorescenceSource</code> class only needs to implement one function: <code>get_source_generators</code> which has to return a list of generators.</p> <p>The generators themselves may be methods of this class, but can be implemented anywhere. The generator is supposed to yield an dranspose.event.InternalWorkerMessage object.</p>"},{"location":"applications/hdf5_stream/#example-with-stins","title":"Example with STINS","text":"<p>To stream 2d images from a hybrid photon counting detector, the following source class could be adapted. The images are read from a HDF5 file.</p> <pre><code>import itertools\n\nfrom dranspose.event import (\n    InternalWorkerMessage,\n    StreamData\n)\nfrom dranspose.data.stream1 import Stream1Start, Stream1Data, Stream1End\nimport h5py\nfrom bitshuffle import compress_lz4\n\nclass FluorescenceSource:\n    def __init__(self):\n        self.fd = h5py.File(\"../000008.h5\")\n\n    def get_source_generators(self):\n        return [self.pilatus_source()]\n\n    def pilatus_source(self):\n        msg_number = itertools.count(0)\n\n        stins_start = Stream1Start(htype=\"header\", filename=\"\", msg_number=next(msg_number)).model_dump_json()\n        start = InternalWorkerMessage(event_number=0, streams={\"pilatus\": StreamData(typ=\"STINS\", frames=[stins_start])})\n        yield start\n\n        frameno = 0\n        for image in self.fd[\"/entry/measurement/pilatus/frames\"]:\n            stins = Stream1Data(htype=\"image\", msg_number=next(msg_number),\n                                frame=frameno, shape=image.shape, compression=\"bslz4\",\n                                type=str(image.dtype)).model_dump_json()\n            dat = compress_lz4(image)\n            img = InternalWorkerMessage(event_number=frameno+1,\n                                          streams={\"pilatus\": StreamData(typ=\"STINS\", frames=[stins, dat.tobytes()])})\n            yield img\n            frameno += 1\n\n        stins_end = Stream1End(htype=\"series_end\", msg_number=next(msg_number)).model_dump_json()\n        end = InternalWorkerMessage(event_number=frameno,\n                                      streams={\"pilatus\": StreamData(typ=\"STINS\", frames=[stins_end])})\n        yield end\n</code></pre> <p>The <code>__init__</code> only opens the <code>.h5</code> file. The mandatory method <code>get_source_generators</code> returns a list with a single generator. This generator <code>pilatus_source</code> then creates an dranspose.data.stream1.Stream1Start object and dumps it to json. The bytes resulting from that dump to json are then first wrapped in dranspose.event.StreamData. Here we used the stream name <code>pilatus</code>, which needs to match the setup at the experiment. Finally, it yields an InternalWorkerMessage.</p> <p>For the data packages, the actual data needs to be returned. For the header we use dranspose.data.stream1.Stream1Data again and dump it to json. For the image, it is important to know if the stream will contain compressed images. In the above case, the stream will send bitshuffle lz4 compressed images. Therefore, we need to recreate the compressed frames with <code>compress_lz4</code>.</p> <p>Warning</p> <p>Beware that you have to manually provide the correct <code>event_number</code> for each yield.</p> <p>In STINS, there is usually a dranspose.data.stream1.Stream1End message, which needs to be yielded.</p>"},{"location":"applications/overview/","title":"Application Development","text":"<p>Unlike sequential processing of data, dranspose leverages parallel processing to achieve the throughput necesary for live processing.</p> <p>We use the map reduce programming model for distributing work. Parallel workers unfortunately have to work independently. Therefore, they only have access to a single event at a time. They may store local state, but don't have access to arbitrary other events.</p> <p>For data analysis which has to cross all events, there is a secondary reduce step which can only cope with reduced data, but gets all events delivered.</p> <p>A lot of common analysis tasks are easily mapped to this programming model. The map phase performs the heavy lifting, e.g. analysing images and then forwards a spectrum to the reducer which only averages the sprectra or appends them to a list.</p>"},{"location":"applications/overview/#using-dranspose","title":"Using <code>dranspose</code>","text":"<p>Note</p> <p>Before developing a new worker functionality, it is necessary to capture events coming from the streams. Please see capturing events. Here we assume that you have dumps for all necessary streams</p> <p>To analyse data with dranspose, you need to split your task into a <code>map</code> and a <code>reduce</code> function.</p> <p>Create a new git repository and create the following structure</p> <pre><code>.\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 reducer.py\n    \u2514\u2500\u2500 worker.py\n</code></pre>"},{"location":"applications/overview/#workerpy","title":"<code>worker.py</code>","text":"<p>The worker gets events and has to first parse the messages from the data stream. Then it reduces the data available and forwards a condensed version.</p> <p>The worker class is instantiated for every new trigger map. This allows to use the <code>__init__</code> for resetting the state. All calls provide the current set of <code>parameters</code> which may be required to set the worker up.</p> <p>Creating a logger is useful for development and production.</p> <p><pre><code>import logging\n\nfrom dranspose.event import EventData\nfrom dranspose.middlewares import contrast\nfrom dranspose.middlewares import xspress\n\nlogger = logging.getLogger(__name__)\n\nclass FluorescenceWorker:\n    def __init__(self, parameters=None, *args, **kwargs):\n        self.number = 0\n</code></pre> The <code>process_event</code> function gets an EventData object which contains all required streams for the current event. The first step should be to check that the required streams for the analyis are present. <pre><code>    def process_event(self, event: EventData, parameters=None, *args, **kwargs):\n        logger.debug(\"using parameters %s\", parameters)\n        if {\"contrast\", \"xspress3\"} - set(event.streams.keys()) != set():\n            logger.error(\n                \"missing streams for this worker, only present %s\", event.streams.keys()\n            )\n            return\n</code></pre> Many streams have the same packet structure and therefore <code>dranspose</code> include middlewares to autmatically parse the frames to python objects. <pre><code>        try:\n            con = contrast.parse(event.streams[\"contrast\"])\n        except Exception as e:\n            logger.error(\"failed to parse contrast %s\", e.__repr__())\n            return\n\n        try:\n            spec = xspress.parse(event.streams[\"xspress3\"])\n        except Exception as e:\n            logger.error(\"failed to parse xspress3 %s\", e.__repr__())\n            return\n        logger.error(\"contrast: %s\", con)\n        logger.error(\"spectrum: %s\", spec)\n</code></pre> Check if we are in an event which produces data. Others may be <code>starting</code> or <code>finishing</code> <pre><code>        if con.status == \"running\":\n            # new data\n            sx, sy = con.pseudo[\"x\"][0], con.pseudo[\"y\"][0]\n            logger.error(\"process position %s %s\", sx, sy)\n\n            roi1 = spec.data[3][parameters[\"roi1\"][0] : parameters[\"roi1\"][1]].sum()\n\n            return {\"position\": (sx, sy), \"concentations\": {\"roi1\": roi1}}\n</code></pre></p> <p>The returned object will be available to the reducer</p>"},{"location":"applications/overview/#reducerpy","title":"<code>reducer.py</code>","text":"<p>The reducer may also have a setup in <code>__init__</code> where is may initialise the special <code>publish</code> attribute. This attribute is automatically exposed via http for live viewers</p> <p><pre><code>from dranspose.event import ResultData\n\nclass FluorescenceReducer:\n    def __init__(self, parameters=None, **kwargs):\n        self.number = 0\n        self.publish = {\"map\": {}}\n</code></pre> In <code>process_result</code>, only simple operations are possible, such as appending to a dictionary, as this has to run at the acquisition speed. <pre><code>    def process_result(self, result: ResultData, parameters=None):\n        print(result)\n        if result.payload:\n            self.publish[\"map\"][result.payload[\"position\"]] = result.payload[\n                \"concentations\"\n            ]\n</code></pre></p>"},{"location":"applications/overview/#developing-an-analysis","title":"Developing an analysis","text":"<p>The worker and reducer is easily tested by the <code>dranspose replay</code> command. Provide the worker class <code>-w</code> and the reducer class <code>-r</code>. You also need to provide the dumped stream from each ingester. If you need parameters, you can provide a json or pickle file which will be provided to your worker functions.</p> <pre><code>LOG_LEVEL=\"DEBUG\" dranspose replay -w \"src.worker:FluorescenceWorker\" \\\n    -r \"src.reducer:FluorescenceReducer\" \\\n    -f ../contrast_ingest.pkls ../xspress_ingest.pkls \\\n    -p ../fullparam.json\n</code></pre>"},{"location":"deployment/capturing/","title":"Capturing Streams","text":"<p>To develop locally, there are 2 possible streams to capture. The raw stream from the device/republishing is useful to develop ingesters for new protocols. The InternalWorkerMessages are already processed by the ingesters and are more useful to develop the worker and reducer code.</p>"},{"location":"deployment/capturing/#raw-streams","title":"Raw Streams","text":"<p>Capturing the raw streams is the first step for a new setup. Figure out a minimal script to listen to the data stream and write the received data to disk. It has to be sufficient to be replayed against an ingester.</p> <p>Here is an example for a zmq SUB socket</p> <pre><code>import zmq\nimport sys\nimport pickle\n\nif len(sys.argv) &lt; 4:\n    print(\"usage: host port file\")\n    sys.exit(0)\n\ncontext = zmq.Context()\n\nsock = context.socket(zmq.SUB)\nsock.connect (\"tcp://%s:%u\" % (sys.argv[1], int(sys.argv[2])))\nsock.setsockopt(zmq.SUBSCRIBE, b\"\")\n\nf = open(sys.argv[3], \"ab\")\ntry:\n    while True:\n        parts = sock.recv_multipart()\n        print(len(parts), parts[0])\n        pickle.dump(parts, f)\nexcept KeyboardInterrupt:\n    print(\"closing file\")\n    f.close()\n</code></pre> <p>This script receives zmq Multipart messages from a publisher and writes them to a sequential pickle file. While dranspose internally uses zmq, ingesters can be used to receive data from other stream formats.</p>"},{"location":"deployment/capturing/#internal-stream","title":"Internal Stream","text":"<p>All ingesters derived from the Ingester class accept a <code>dump_path</code> setting. If this is set, the ingester will write all data which is sent out to the workers also to a file.</p>"},{"location":"deployment/capturing/#pickles-format","title":"Pickles Format","text":"<p>As pickled objects have a length information in the header, it is possible to write consecutive pickle dumps into the same file. The file is then read without any seeking like this:</p> <pre><code>pkgs = []\nwith open(\"ingest-dump.pkls\",\"rb\") as f:\n    while True:\n        try:\n            frames = pickle.load(f)\n            pkgs.append(frames)\n        except EOFError:\n            break\n</code></pre>"},{"location":"deployment/kubernetes/","title":"K8s deployment","text":"<p>The most easy way to run a distributed version of dranspose is via a helm chart.</p>"},{"location":"deployment/kubernetes/#values","title":"Values","text":"<p>The required values are a <code>beamline</code> to be able to mount the correct volumes. The <code>dump_prefix</code> may be set to a path to which the ingesters dump all stream messages. This is useful to get the initial data to develop a worker which can digest these.</p> <p>The <code>ingesters</code> map specifies the name of the stream, the <code>upstream_url</code> on where to connect to and the class. Other ingesters may need additional settings.  If the stream name contains underscores, a separate <code>stream</code> entry can be used as k8s does not allow underscore in deployment names.</p> <p>The <code>workers</code> and the <code>reducer</code> run with a custom docker image which contains all the dependencies for the analysis <code>worker.class</code> and <code>reducer.class</code> specify the paths to the correct classes in the analysis container.</p> <pre><code>global:\n  beamline: nanomax\n  dump_prefix: false #\"/data/staff/dummymax/dumps/ingest_dump_\"\n\ningesters:\n  contrast:\n    upstream_url: \"tcp://172.16.125.30:5556\"\n    ingester_class: \"StreamingContrastIngester\"\n    stream: \"contrast_one\"\n  xspress3:\n    upstream_url: \"tcp://172.16.126.70:9999\"\n    ingester_class: \"StreamingXspressIngester\"\n\nscience_image: \"harbor.maxiv.lu.se/daq/dranspose/nanomax-fluorescence:main\"\n\nworker:\n  class: \"src.worker:FluorescenceWorker\"\nreducer:\n  class: \"src.worker:FluorescenceReducer\"\n</code></pre>"},{"location":"deployment/sardana/","title":"Sardana integration","text":"<p>The scanning software sardana allows to create pre-scan hooks to notify dranspose of an upcoming scan.</p> <p>An example hook looks like.</p> <pre><code>__all__ = [\"dranspose\"]\n\nfrom sardana.macroserver.macro import macro, Macro, Type, Optional\nfrom tango import DeviceProxy\nimport json\nimport requests\n\nclass dranspose(Macro):\n    \"\"\"Notify a dranspose Pipeline of a scan\"\"\"\n    param_def = [['url', Type.String, None, \"url to the pipeline controller\"]]\n\n    def run(self, url):\n        active_mnt_group = self.getEnv(\"ActiveMntGrp\")\n\n        # Device proxy to active measurement group\n        active_mnt_group_dp = DeviceProxy(active_mnt_group)\n        # Controllers on active measurement group\n        mg_configuration = json.loads(active_mnt_group_dp.Configuration)\n        controllers = mg_configuration[\"controllers\"]\n\n        self.output(f\"dranspose triggermap to {url}\")\n        self.output(\"streams in measurement group:\")\n        streams = []\n        for conf in controllers.values():\n            for ch in conf[\"channels\"].values():\n                if ch[\"enabled\"] is True:\n                    self.output(ch[\"name\"])\n                    streams.append(ch[\"name\"])\n\n        if self._parent_macro is not None:\n            # build triggermap depending on the type of scan\n            if self._parent_macro._name == \"burstscan\":\n                burst = -self._parent_macro.integ_time\n                steps = self._parent_macro.nb_points\n                # only create frames for detectors which have ingesters\n                available_streams = [\"andor3_balor\", \"andor3_zyla10\", \"andor3_zyla12\", \"pilatus\"]\n                mapping = {det:[\n                    [{\"constraint\":i}] for i in range(burst*steps)]\n                    for det in available_streams if det in streams}\n                mapping[\"sardana\"] = [[{\"constraint\":i}] if \n                                      i%burst==burst-1 else \n                                      None for i in range(burst*steps)]\n                req = requests.post(f\"{url}/api/v1/mapping\", json=mapping)\n                self.output(f\"{req.status_code}, msg: {req.content}\")\n</code></pre> <p>The hook is then enabled with</p> <pre><code>defgh \"dranspose http://femtomax-pipeline-controller.daq.maxiv.lu.se\" pre-scan\n</code></pre>"},{"location":"reference/middlewares/","title":"Middlewares","text":"<p>Small helpers to parse the binary frames in the workers.</p>"},{"location":"reference/middlewares/#contrast","title":"Contrast","text":""},{"location":"reference/middlewares/#dranspose.middlewares.contrast.parse","title":"<code>parse(data)</code>","text":"<p>Parses a contrast packet, which returns a dict, depending on the status of contrast</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>StreamData</code> <p>a frame comming from contrast</p> required <p>Returns:</p> Type Description <code>UnionType</code> <p>a ContrastPacket containing a.o. the current status</p> Source code in <code>dranspose/middlewares/contrast.py</code> <pre><code>def parse(data: StreamData) -&gt; UnionType:\n    \"\"\"\n    Parses a contrast packet, which returns a dict, depending on the status of contrast\n\n    Arguments:\n        data: a frame comming from contrast\n\n    Returns:\n        a ContrastPacket containing a.o. the current status\n    \"\"\"\n    assert data.typ == \"contrast\", \"wrong stream name\"\n    assert data.length == 1, \"multipart must be 1\"\n    frame = data.frames[0]\n    if isinstance(frame, zmq.Frame):\n        val = pickle.loads(frame.bytes)\n    else:\n        val = pickle.loads(frame)\n\n    return ContrastPacket.validate_python(val)\n</code></pre>"},{"location":"reference/middlewares/#xspress3","title":"Xspress3","text":""},{"location":"reference/middlewares/#dranspose.middlewares.xspress.parse","title":"<code>parse(data)</code>","text":"<p>Parses a Xspress3 packet, which either gives a start/end message or a tuple with a spectra array</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>StreamData</code> <p>a frame comming from the Xspress3 tango device</p> required <p>Returns:</p> Type Description <code>UnionType</code> <p>an XspressPacket</p> Source code in <code>dranspose/middlewares/xspress.py</code> <pre><code>def parse(\n    data: StreamData,\n) -&gt; UnionType:\n    \"\"\"\n    Parses a Xspress3 packet, which either gives a start/end message or a tuple with a spectra array\n\n    Arguments:\n        data: a frame comming from the Xspress3 tango device\n\n    Returns:\n        an XspressPacket\n    \"\"\"\n    assert data.typ == \"xspress\", \"wrong packet typ\"\n    assert data.length &gt;= 1, \"wrong number of multiparts\"\n    headerframe = data.frames[0]\n    if isinstance(headerframe, zmq.Frame):\n        headerframe = headerframe.bytes\n    packet = XspressPacket.validate_json(headerframe)\n    print(\"packets\", packet)\n    if isinstance(packet, XspressImage):\n        assert data.length == 3, \"images does not contain data\"\n        bufframe = data.frames[1]\n        if isinstance(bufframe, zmq.Frame):\n            bufframe = bufframe.bytes\n        buf = np.frombuffer(bufframe, dtype=packet.type)\n        img = buf.reshape(packet.shape)\n        metaframe = data.frames[2]\n        if isinstance(metaframe, zmq.Frame):\n            metaframe = metaframe.bytes\n        meta = pickle.loads(metaframe)\n        # meta description: ocr[0], AllEvents[0], AllGood[0], ClockTicks[0],\n        #                   TotalTicks[0], ResetTicks[0], event_widths, dtc[0]]\n        meta = {\n            k: v\n            for k, v in zip(\n                [\n                    \"ocr\",\n                    \"AllEvents\",\n                    \"AllGood\",\n                    \"ClockTicks\",\n                    \"TotalTicks\",\n                    \"ResetTicks\",\n                    \"event_widths\",\n                    \"dtc\",\n                ],\n                meta,\n            )\n        }\n        packet.data = img\n        packet.meta = meta\n\n    return packet\n</code></pre>"},{"location":"reference/trigger_map/","title":"Trigger Map","text":"<p>The trigger map is the core part of dranspose and answers the following question:</p> <p>Question</p> <p>Which frames from which streams belong to the same event and have to be processed by the same worker with which tags?</p> <p>It is a matrix which can express all required combinations. Instead of assigning workers directly, the trigger map only holds virtual workers. A guarantee is that if the same virtual worker is responsible for two frames, the same real worker will get both.</p>"},{"location":"reference/trigger_map/#virtual-workers","title":"Virtual Workers","text":"<p>A virtual worker hold a list of tags, which must be a subset of the tags held by the actual worker.</p> <p>An optional containt can be applied such that frames with the same constraint are delivered to the same worker. Note that for a new constraint, only the first VirtualWorker tags are considered as subsequent frames are necessarily delivered to the same actual worker with the same tags. If the constraint is None, the frame is delivered to all workers which satisfy the tags.</p>"},{"location":"reference/trigger_map/#example-without-tags","title":"Example without Tags","text":"Stream Event 1 Event 2 Event 3 Event 4 Event 5 Event 6 stream 1 all [1] [1] [3] [3] [5] stream 2 all [2] [2] [4] [4] [5] low all [1,2] [] [3,4] [] [5] slow all all none none none all <ul> <li>The first frame of all streams is distribute to all workers.</li> <li>The next 4 frames of stream 1 are pairwise distributed to the same worker (first 1, then 3).</li> <li>Virtual workers 1 and 3 might be the same physical one, but it is not guaranteed</li> <li>The last frame of stream 1 and stream 2 are delivered to the same worker</li> <li>The second frame of low is deliverd to the same workers which are processing the second frame of stream 1 and stream 2</li> <li>The third frame of low is delivered to no workers, i.e. discarded</li> <li>The thrid, fourth and fifth event has no frame from slow, this is useful for mixing streams with different sample frequencies.</li> </ul>"},{"location":"reference/trigger_map/#trigger-map-format","title":"Trigger map format","text":"<p>The type of a trigger map is</p> <pre><code>Dict[StreamName, List[Optional[List[VirtualWorker]]]]\n</code></pre> <p>This is an example with te generic workers only. <pre><code>{\n    \"eiger\": [\n        [{\"tags\": [\"generic\"], \"constraint\": 2}],\n        [{\"tags\": [\"generic\"], \"constraint\": 4}],\n        [{\"tags\": [\"generic\"], \"constraint\": 6}],\n        [{\"tags\": [\"generic\"], \"constraint\": 8}],\n        [{\"tags\": [\"generic\"], \"constraint\": 10}],\n        [{\"tags\": [\"generic\"], \"constraint\": 12}],\n        [{\"tags\": [\"generic\"], \"constraint\": 14}],\n        [{\"tags\": [\"generic\"], \"constraint\": 16}],\n        [{\"tags\": [\"generic\"], \"constraint\": 18}]\n    ],\n    \"orca\": [\n        [{\"tags\": [\"generic\"], \"constraint\": 3}],\n        [{\"tags\": [\"generic\"], \"constraint\": 5}],\n        [{\"tags\": [\"generic\"], \"constraint\": 7}],\n        [{\"tags\": [\"generic\"], \"constraint\": 9}],\n        [{\"tags\": [\"generic\"], \"constraint\": 11}],\n        [{\"tags\": [\"generic\"], \"constraint\": 13}],\n        [{\"tags\": [\"generic\"], \"constraint\": 15}],\n        [{\"tags\": [\"generic\"], \"constraint\": 17}],\n        [{\"tags\": [\"generic\"], \"constraint\": 19}]\n    ],\n    \"alba\": [\n        [\n            {\"tags\": [\"generic\"], \"constraint\": 2},\n            {\"tags\": [\"generic\"], \"constraint\": 3}\n        ],\n        [\n            {\"tags\": [\"generic\"], \"constraint\": 4},\n            {\"tags\": [\"generic\"], \"constraint\": 5}\n        ],\n        [\n            {\"tags\": [\"generic\"], \"constraint\": 6},\n            {\"tags\": [\"generic\"], \"constraint\": 7}\n        ],\n        [\n            {\"tags\": [\"generic\"], \"constraint\": 8},\n            {\"tags\": [\"generic\"], \"constraint\": 9}\n        ],\n        [\n            {\"tags\": [\"generic\"], \"constraint\": 10},\n            {\"tags\": [\"generic\"], \"constraint\": 11}\n        ],\n        [\n            {\"tags\": [\"generic\"], \"constraint\": 12},\n            {\"tags\": [\"generic\"], \"constraint\": 13}\n        ],\n        [\n            {\"tags\": [\"generic\"], \"constraint\": 14},\n            {\"tags\": [\"generic\"], \"constraint\": 15}\n        ],\n        [\n            {\"tags\": [\"generic\"], \"constraint\": 16},\n            {\"tags\": [\"generic\"], \"constraint\": 17}\n        ],\n        [\n            {\"tags\": [\"generic\"], \"constraint\": 18},\n            {\"tags\": [\"generic\"], \"constraint\": 19}\n        ]\n    ],\n    \"slow\": [\n        null,\n        null,\n        null,\n        [\n            {\"tags\": [\"generic\"], \"constraint\": 8},\n            {\"tags\": [\"generic\"], \"constraint\": 9}\n        ],\n        null,\n        null,\n        null,\n        [\n            {\"tags\": [\"generic\"], \"constraint\": 16},\n            {\"tags\": [\"generic\"], \"constraint\": 17}\n        ],\n        null\n    ]\n}\n</code></pre></p>"},{"location":"reference/internals/controller/","title":"Controller","text":""},{"location":"reference/internals/controller/#scan-sequence","title":"Scan Sequence","text":"<pre><code>sequenceDiagram\n    participant API\n    participant Controller\n    participant Ingester\n    participant Worker\n    participant Reducer\n    API -&gt;&gt;+ Controller: set_mapping\n    Controller -&gt;&gt; Redis/Updates: ControllerUpdate\n\n    Redis/Updates -&gt;&gt; Worker: read updates\n    Worker-&gt;&gt;Worker: restart_work\n    Worker -&gt;&gt; Redis/Config: distributed new state\n    Redis/Config -&gt;&gt; Controller: wait for all components to have the new state\n    Controller -&gt;&gt;- API: mapping applied\n    Worker -&gt;&gt; Redis/Ready/uuid: worker ready\n\n    loop Until all events and results are done\n        Redis/Ready/uuid -&gt;&gt; Controller: Get idle worker\n        Controller -&gt;&gt; Controller: assign worker to map\n        Controller -&gt;&gt; Redis/Assigned/uuid: publish batch of assigned workers to events\n        Redis/Assigned/uuid -&gt;&gt; Ingester: get workers for next event\n        Ingester -&gt;&gt; Ingester: read next frame from ZMQ\n        Redis/Assigned/uuid -&gt;&gt; Worker: get ingesters for next event\n        Ingester -&gt;&gt; Worker: Partial Event, ZMQ\n        Worker -&gt;&gt; Worker: assemble and process Event\n        alt Result is not None\n            Worker -&gt;&gt; Reducer: Result, ZMQ\n            Reducer -&gt;&gt; Reducer: process Result\n            Reducer -&gt;&gt; Redis/Ready/uuid: Result done\n        end\n        Worker -&gt;&gt; Redis/Ready/uuid: Events done, batched\n    end\n    Redis/Ready/uuid -&gt;&gt; Controller: wait for all components to have processed everything\n    Controller -&gt;&gt; Redis/Updates: finished map\n    Redis/Updates -&gt;&gt; Worker: get finished\n    Worker -&gt;&gt; Redis/Ready/uuid: finished done\n    Redis/Ready/uuid -&gt;&gt; Controller: wait for all components to finish\n</code></pre>"},{"location":"reference/internals/distributed_service/","title":"Distributed service","text":""},{"location":"reference/internals/distributed_service/#dranspose.distributed.DistributedService","title":"<code>DistributedService</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract class defining common functionality for all services.</p> Source code in <code>dranspose/distributed.py</code> <pre><code>class DistributedService(abc.ABC):\n    \"\"\"\n    Abstract class defining common functionality for all services.\n    \"\"\"\n\n    def __init__(\n        self,\n        state: WorkerState | IngesterState | ReducerState,\n        settings: Optional[DistributedSettings] = None,\n    ):\n        self._distributed_settings = settings\n        if self._distributed_settings is None:\n            self._distributed_settings = DistributedSettings()\n\n        self.state: WorkerState | IngesterState | ReducerState = state\n\n        if \":\" in state.name:\n            raise Exception(\"Worker name must not contain a :\")\n        # TODO: check for already existing query string\n        self.redis = redis.from_url(\n            f\"{self._distributed_settings.redis_dsn}?decode_responses=True&amp;protocol=3\"\n        )\n        self.raw_redis = redis.from_url(\n            f\"{self._distributed_settings.redis_dsn}?protocol=3\"\n        )\n        self._logger = logging.getLogger(f\"{__name__}+{self.state.name}\")\n        self._logger.info(\"log handlers are %s\", self._logger.handlers)\n        try:\n            if self._distributed_settings.build_meta_file is not None:\n                with open(self._distributed_settings.build_meta_file) as fd:\n                    build_data = BuildGitMeta.model_validate_json(fd.read())\n                    self._logger.info(\"build meta is %s\", build_data)\n                    self.state.mapreduce_version = build_data\n        except Exception as e:\n            logging.info(\"cannot load build meta information: %s\", e.__repr__())\n        self.state.dranspose_version = version(\"dranspose\")\n        self._logger.info(\"running version %s\", self.state.dranspose_version)\n        self.parameters: dict[ParameterName, WorkParameter] = {}\n\n    def get_category(self) -&gt; str:\n        if isinstance(self.state, IngesterState):\n            category = \"ingester\"\n        elif isinstance(self.state, WorkerState):\n            category = \"worker\"\n        elif isinstance(self.state, ReducerState):\n            category = \"reducer\"\n        else:\n            raise NotImplementedError(\n                \"Distributed Service not implemented for your Service\"\n            )\n        return category\n\n    async def publish_config(self) -&gt; None:\n        self._logger.debug(\"publish config %s\", self.state)\n        async with self.redis.pipeline() as pipe:\n            await pipe.setex(\n                RedisKeys.config(self.get_category(), self.state.name),\n                10,\n                self.state.model_dump_json(),\n            )\n            if hasattr(self, \"param_descriptions\"):\n                for p in self.param_descriptions:\n                    self._logger.debug(\"register parameter %s\", p)\n                    try:\n                        await pipe.setex(\n                            RedisKeys.parameter_description(p.name),\n                            10,\n                            p.model_dump_json(),\n                        )\n                    except Exception as e:\n                        self._logger.error(\n                            \"failed to register parameter %s\", e.__repr__()\n                        )\n\n            await pipe.execute()\n\n    async def register(self) -&gt; None:\n        \"\"\"\n        Background job in every distributed service to publish the service's configuration.\n        It publishes the `state` every 1.3 seconds or faster if there are updates from the controller with a new trigger map or parameters.\n        \"\"\"\n        latest = await self.redis.xrevrange(RedisKeys.updates(), count=1)\n        last = 0\n        if len(latest) &gt; 0:\n            last = latest[0][0]\n        while True:\n            await self.publish_config()\n            try:\n                update_msgs = await self.redis.xread(\n                    {RedisKeys.updates(): last}, block=1300\n                )\n                if RedisKeys.updates() in update_msgs:\n                    update_msg = update_msgs[RedisKeys.updates()][0][-1]\n                    last = update_msg[0]\n                    update = ControllerUpdate.model_validate_json(update_msg[1][\"data\"])\n                    self._logger.debug(\"update type %s\", update)\n                    newuuid = update.mapping_uuid\n                    if newuuid != self.state.mapping_uuid:\n                        self._logger.info(\n                            \"resetting config to %s with streams %s\",\n                            newuuid,\n                            update.active_streams,\n                        )\n                        try:\n                            await self.restart_work(newuuid, update.active_streams)\n                        except Exception as e:\n                            self._logger.error(\"restart_work failed %s\", e.__repr__())\n                    paramuuids = update.parameters_version\n                    for name in paramuuids:\n                        if (\n                            name not in self.parameters\n                            or self.parameters[name] != paramuuids[name]\n                        ):\n                            try:\n                                params = await self.raw_redis.get(\n                                    RedisKeys.parameters(name, paramuuids[name])\n                                )\n                                self._logger.debug(\n                                    \"received binary parameters for %s\", name\n                                )\n                                if params is not None:\n                                    self._logger.info(\n                                        \"set parameter %s of length %s\",\n                                        name,\n                                        len(params),\n                                    )\n                                    self.parameters[name] = WorkParameter(\n                                        name=name, uuid=paramuuids[name], data=params\n                                    )\n                                    # check if this parameter has a description and type\n                                    desc = await self.redis.get(\n                                        RedisKeys.parameter_description(name),\n                                    )\n                                    self._logger.debug(\"description is %s\", desc)\n                                    if desc:\n                                        param_desc: ParameterType = (\n                                            Parameter.validate_json(desc)\n                                        )\n                                        self._logger.info(\n                                            \"set paremter has a description %s\",\n                                            param_desc,\n                                        )\n                                        self.parameters[\n                                            name\n                                        ].value = param_desc.from_bytes(params)\n                                        self._logger.debug(\n                                            \"parsed parameter value %s\",\n                                            self.parameters[name].value,\n                                        )\n                            except Exception as e:\n                                self._logger.error(\n                                    \"failed to get parameters %s\", e.__repr__()\n                                )\n                    self.state.parameters_hash = parameters_hash(self.parameters)\n                    self._logger.debug(\n                        \"set local parameters to %s with hash %s\",\n                        {n: p.uuid for n, p in self.parameters.items()},\n                        self.state.parameters_hash,\n                    )\n                    if update.finished:\n                        self._logger.info(\"finished messages\")\n                        await self.finish_work()\n\n            except rexceptions.ConnectionError:\n                break\n            except asyncio.exceptions.CancelledError:\n                break\n\n    async def multiprocess_run(self, queue: Any) -&gt; None:\n        task = asyncio.create_task(self.run())\n        loop = asyncio.get_event_loop()\n        await loop.run_in_executor(None, queue.get)\n        await self.close()\n        await cancel_and_wait(task)\n\n    def sync_run(self, queue: Any) -&gt; None:\n        asyncio.run(self.multiprocess_run(queue))\n\n    async def update_metrics(self) -&gt; None:\n        while True:\n            start = time.time()\n            old = self.state.processed_events\n            await asyncio.sleep(1.0)\n            end = time.time()\n            rate = (self.state.processed_events - old) / (end - start)\n            self.state.event_rate = rate\n            if (self.state.processed_events - old) &gt; 0:\n                self._logger.info(\"receiving %lf frames per second\", rate)\n\n    async def run(self) -&gt; None:\n        pass\n\n    async def restart_work(self, uuid: UUID4, active_streams: list[StreamName]) -&gt; None:\n        pass\n\n    async def finish_work(self) -&gt; None:\n        pass\n\n    async def close(self) -&gt; None:\n        await self.redis.delete(RedisKeys.config(self.get_category(), self.state.name))\n        self._logger.info(\n            \"deleted redis key %s\",\n            RedisKeys.config(self.get_category(), self.state.name),\n        )\n        await self.redis.aclose()\n        await self.raw_redis.aclose()\n</code></pre>"},{"location":"reference/internals/distributed_service/#dranspose.distributed.DistributedService.register","title":"<code>register()</code>  <code>async</code>","text":"<p>Background job in every distributed service to publish the service's configuration. It publishes the <code>state</code> every 1.3 seconds or faster if there are updates from the controller with a new trigger map or parameters.</p> Source code in <code>dranspose/distributed.py</code> <pre><code>async def register(self) -&gt; None:\n    \"\"\"\n    Background job in every distributed service to publish the service's configuration.\n    It publishes the `state` every 1.3 seconds or faster if there are updates from the controller with a new trigger map or parameters.\n    \"\"\"\n    latest = await self.redis.xrevrange(RedisKeys.updates(), count=1)\n    last = 0\n    if len(latest) &gt; 0:\n        last = latest[0][0]\n    while True:\n        await self.publish_config()\n        try:\n            update_msgs = await self.redis.xread(\n                {RedisKeys.updates(): last}, block=1300\n            )\n            if RedisKeys.updates() in update_msgs:\n                update_msg = update_msgs[RedisKeys.updates()][0][-1]\n                last = update_msg[0]\n                update = ControllerUpdate.model_validate_json(update_msg[1][\"data\"])\n                self._logger.debug(\"update type %s\", update)\n                newuuid = update.mapping_uuid\n                if newuuid != self.state.mapping_uuid:\n                    self._logger.info(\n                        \"resetting config to %s with streams %s\",\n                        newuuid,\n                        update.active_streams,\n                    )\n                    try:\n                        await self.restart_work(newuuid, update.active_streams)\n                    except Exception as e:\n                        self._logger.error(\"restart_work failed %s\", e.__repr__())\n                paramuuids = update.parameters_version\n                for name in paramuuids:\n                    if (\n                        name not in self.parameters\n                        or self.parameters[name] != paramuuids[name]\n                    ):\n                        try:\n                            params = await self.raw_redis.get(\n                                RedisKeys.parameters(name, paramuuids[name])\n                            )\n                            self._logger.debug(\n                                \"received binary parameters for %s\", name\n                            )\n                            if params is not None:\n                                self._logger.info(\n                                    \"set parameter %s of length %s\",\n                                    name,\n                                    len(params),\n                                )\n                                self.parameters[name] = WorkParameter(\n                                    name=name, uuid=paramuuids[name], data=params\n                                )\n                                # check if this parameter has a description and type\n                                desc = await self.redis.get(\n                                    RedisKeys.parameter_description(name),\n                                )\n                                self._logger.debug(\"description is %s\", desc)\n                                if desc:\n                                    param_desc: ParameterType = (\n                                        Parameter.validate_json(desc)\n                                    )\n                                    self._logger.info(\n                                        \"set paremter has a description %s\",\n                                        param_desc,\n                                    )\n                                    self.parameters[\n                                        name\n                                    ].value = param_desc.from_bytes(params)\n                                    self._logger.debug(\n                                        \"parsed parameter value %s\",\n                                        self.parameters[name].value,\n                                    )\n                        except Exception as e:\n                            self._logger.error(\n                                \"failed to get parameters %s\", e.__repr__()\n                            )\n                self.state.parameters_hash = parameters_hash(self.parameters)\n                self._logger.debug(\n                    \"set local parameters to %s with hash %s\",\n                    {n: p.uuid for n, p in self.parameters.items()},\n                    self.state.parameters_hash,\n                )\n                if update.finished:\n                    self._logger.info(\"finished messages\")\n                    await self.finish_work()\n\n        except rexceptions.ConnectionError:\n            break\n        except asyncio.exceptions.CancelledError:\n            break\n</code></pre>"},{"location":"reference/internals/distributed_service/#dranspose.distributed.DistributedSettings","title":"<code>DistributedSettings</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Basic settings for any distributed service</p> <p>Attributes:</p> Name Type Description <code>redis_dsn</code> <code>RedisDsn</code> <p>URL of the common redis instance</p> Source code in <code>dranspose/distributed.py</code> <pre><code>class DistributedSettings(BaseSettings):\n    \"\"\"\n    Basic settings for any distributed service\n\n    Attributes:\n        redis_dsn: URL of the common redis instance\n    \"\"\"\n\n    redis_dsn: RedisDsn = Field(\n        Url(\"redis://localhost:6379/0\"),\n        validation_alias=AliasChoices(\"service_redis_dsn\", \"redis_url\"),\n    )\n\n    build_meta_file: Optional[os.PathLike[Any] | str] = \"/etc/build_git_meta.json\"\n</code></pre>"},{"location":"reference/internals/ingester/","title":"Ingester","text":""},{"location":"reference/internals/ingester/#sequence-diagram","title":"Sequence Diagram","text":"<pre><code>sequenceDiagram\n    Ingester -&gt;&gt;+ accept_workers: run\n    Ingester -&gt;&gt;+ work: run\n    Ingester -&gt;&gt;+ manage_assignments: run\n    Ingester -&gt;&gt;+ update_metrics: run\n    Ingester -&gt;&gt;+ register: run\n\n\n    work -&gt;&gt;- Ingester: restart work\n    manage_assignments -&gt;&gt;- Ingester: restart work\n    Ingester -&gt;&gt;+ work: restart work\n    Ingester -&gt;&gt;+ manage_assignments: restart work\n\n    accept_workers -&gt;&gt;- Ingester: close\n    work -&gt;&gt;- Ingester: close\n    update_metrics -&gt;&gt;- Ingester: close\n    manage_assignments -&gt;&gt;- Ingester: close\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester","title":"<code>Ingester</code>","text":"<p>               Bases: <code>DistributedService</code></p> <p>The Ingester class provides a basis to write custom ingesters for any protocol. It handles all the forwarding to workers and managing assignments. For the instance to do anything, await <code>run()</code></p> Source code in <code>dranspose/ingester.py</code> <pre><code>class Ingester(DistributedService):\n    \"\"\"\n    The Ingester class provides a basis to write custom ingesters for any protocol.\n    It handles all the forwarding to workers and managing assignments.\n    For the instance to do anything, await `run()`\n    \"\"\"\n\n    def __init__(self, settings: Optional[IngesterSettings] = None):\n        if settings is None:\n            settings = IngesterSettings()\n        self._ingester_settings = settings\n        state = IngesterState(\n            name=self._ingester_settings.ingester_name,\n            url=self._ingester_settings.ingester_url,\n            streams=self._ingester_settings.ingester_streams,\n        )\n\n        super().__init__(state=state, settings=self._ingester_settings)\n        self._logger.info(\n            \"created ingester with state %s and settings %s\",\n            state,\n            self._ingester_settings,\n        )\n        self.state: IngesterState\n        self.active_streams: list[StreamName] = []\n\n        self.dump_file: Optional[BufferedWriter] = None\n\n    def open_socket(self) -&gt; None:\n        self.ctx = zmq.asyncio.Context()\n        self.out_socket = self.ctx.socket(zmq.ROUTER)\n        self.out_socket.setsockopt(zmq.ROUTER_MANDATORY, 1)\n        self.out_socket.setsockopt(zmq.TCP_KEEPALIVE, 1)\n        self.out_socket.setsockopt(zmq.TCP_KEEPALIVE_IDLE, 300)\n        self.out_socket.setsockopt(zmq.TCP_KEEPALIVE_INTVL, 300)\n        self.out_socket.bind(f\"tcp://*:{self._ingester_settings.ingester_url.port}\")\n\n    async def run(self) -&gt; None:\n        \"\"\"\n        Main function orchestrating the dependent tasks. This needs to be called from an async context once an instance is created.\n        \"\"\"\n        try:\n            self.open_socket()\n        except Exception as e:\n            self._logger.error(\n                \"unable to open inward facing router socket %s\", e.__repr__()\n            )\n\n        self.accept_task = asyncio.create_task(self.accept_workers())\n        self.accept_task.add_done_callback(done_callback)\n        self.work_task = asyncio.create_task(self.work())\n        self.work_task.add_done_callback(done_callback)\n        self.assign_task = asyncio.create_task(self.manage_assignments())\n        self.assign_task.add_done_callback(done_callback)\n        self.assignment_queue: asyncio.Queue[WorkAssignment] = asyncio.Queue()\n        self.metrics_task = asyncio.create_task(self.update_metrics())\n        self.metrics_task.add_done_callback(done_callback)\n        self._logger.info(\"all subtasks running\")\n        await self.register()\n\n    async def restart_work(\n        self, new_uuid: UUID4, active_streams: list[StreamName]\n    ) -&gt; None:\n        \"\"\"\n        Restarts all work related tasks to make sure no old state is present in a new scan.\n\n        Arguments:\n            new_uuid: The uuid of the new mapping\n        \"\"\"\n        await cancel_and_wait(self.work_task)\n        await cancel_and_wait(self.assign_task)\n        self.state.mapping_uuid = new_uuid\n        self.active_streams = list(set(active_streams).intersection(self.state.streams))\n        self.assignment_queue = asyncio.Queue()\n        self.work_task = asyncio.create_task(self.work())\n        self.work_task.add_done_callback(done_callback)\n        self.assign_task = asyncio.create_task(self.manage_assignments())\n        self.assign_task.add_done_callback(done_callback)\n\n    async def finish_work(self) -&gt; None:\n        \"\"\"\n        This hook is called when all events of a trigger map were ingested. It is useful for e.g. closing open files.\n        \"\"\"\n        self._logger.info(\"finishing work\")\n        if self.dump_file:\n            self.dump_file.close()\n            self._logger.info(\"closed dump file at finish %s\", self.dump_file)\n            self.dump_file = None\n\n        await self.redis.xadd(\n            RedisKeys.ready(self.state.mapping_uuid),\n            {\n                \"data\": IngesterUpdate(\n                    state=DistributedStateEnum.FINISHED,\n                    ingester=self.state.name,\n                ).model_dump_json()\n            },\n        )\n\n    async def manage_assignments(self) -&gt; None:\n        \"\"\"\n        A background task reading assignments from the controller, filering them for the relevant ones and enqueueing them for when the frame arrives.\n        \"\"\"\n        self._logger.info(\"started ingester manage assign task\")\n        lastev = 0\n        while True:\n            sub = RedisKeys.assigned(self.state.mapping_uuid)\n            try:\n                assignments = await self.redis.xread({sub: lastev}, block=1000)\n            except rexceptions.ConnectionError:\n                break\n            if sub not in assignments:\n                continue\n            assignment_evs = assignments[sub][0]\n            self._logger.debug(\"got assignments %s\", assignment_evs)\n            for assignment in assignment_evs:\n                was = WorkAssignmentList.validate_json(assignment[1][\"data\"])\n                for wa in was:\n                    mywa = wa.get_workers_for_streams(self.active_streams)\n                    if len(mywa.assignments) &gt; 0:\n                        await self.assignment_queue.put(mywa)\n                lastev = assignment[0]\n\n    async def _send_workermessages(\n        self, workermessages: dict[WorkerName, InternalWorkerMessage]\n    ) -&gt; None:\n        for worker, message in workermessages.items():\n            self._logger.debug(\n                \"header is %s\",\n                message.model_dump_json(exclude={\"streams\": {\"__all__\": \"frames\"}}),\n            )\n            await self.out_socket.send_multipart(\n                [worker.encode(\"ascii\")]\n                + [\n                    message.model_dump_json(\n                        exclude={\"streams\": {\"__all__\": \"frames\"}}\n                    ).encode(\"utf8\")\n                ]\n                + message.get_all_frames()\n            )\n            self._logger.debug(\"sent message to worker %s\", worker)\n\n    async def _get_zmqparts(\n        self,\n        work_assignment: WorkAssignment,\n        sourcegens: dict[\n            StreamName, AsyncGenerator[StreamData | IsSoftwareTriggered, None]\n        ],\n        swtriggen: Iterator[dict[StreamName, StreamData]] | None,\n    ) -&gt; dict[StreamName, StreamData]:\n        zmqyields: list[Awaitable[StreamData | IsSoftwareTriggered]] = []\n        streams: list[StreamName] = []\n        for stream in work_assignment.assignments:\n            zmqyields.append(anext(sourcegens[stream]))\n            streams.append(stream)\n        try:\n            zmqstreams: list[StreamData | IsSoftwareTriggered] = await asyncio.gather(\n                *zmqyields\n            )\n        except StopAsyncIteration:\n            self._logger.warning(\"stream source stopped before end\")\n            raise asyncio.exceptions.CancelledError()\n        zmqparts: dict[StreamName, StreamData | IsSoftwareTriggered] = {\n            stream: zmqpart for stream, zmqpart in zip(streams, zmqstreams)\n        }\n        self._logger.debug(\"stream triggered zmqparts %s\", zmqparts)\n        if swtriggen is not None:\n            swparts = next(swtriggen)\n            zmqparts.update(swparts)\n            # that has to overwrite all IsSoftwareTriggered instance\n\n        return zmqparts\n\n    async def work(self) -&gt; None:\n        \"\"\"\n        The heavy liftig function of an ingester. It consumes a generator `run_source()` which\n        should be implemented for a specific protocol.\n        It then assembles all streams for this ingester and forwards them to the assigned workers.\n\n        Optionally the worker dumps the internal messages to disk. This is useful to develop workers with actual data captured.\n        \"\"\"\n        self._logger.info(\"started ingester work task\")\n        sourcegens = {stream: self.run_source(stream) for stream in self.active_streams}\n        if len(sourcegens) == 0:\n            self._logger.warning(\"this ingester has no active streams, stopping worker\")\n            return\n        swtriggen: Iterator[dict[StreamName, StreamData]] | None = None\n        if hasattr(self, \"software_trigger\"):\n            swtriggen = self.software_trigger()\n        self.dump_file = None\n        self.dump_filename = self._ingester_settings.dump_path\n        if self.dump_filename is None and \"dump_prefix\" in self.parameters:\n            val = self.parameters[ParameterName(\"dump_prefix\")].data.decode(\"utf8\")\n            if len(val) &gt; 0:\n                self.dump_filename = f\"{val}{self._ingester_settings.ingester_name}-{self.state.mapping_uuid}.cbors\"\n        if self.dump_filename:\n            self.dump_file = open(self.dump_filename, \"ab\")\n            self._logger.info(\n                \"dump file %s opened at %s\",\n                self.dump_filename,\n                self.dump_file,\n            )\n        try:\n            took = []\n            empties = []\n            while True:\n                empty = False\n                if self.assignment_queue.empty():\n                    empty = True\n                start = time.perf_counter()\n                work_assignment: WorkAssignment = await self.assignment_queue.get()\n                if empty:\n                    empties.append(work_assignment.event_number)\n\n                zmqparts = await self._get_zmqparts(\n                    work_assignment, sourcegens, swtriggen\n                )\n\n                if self.dump_file:\n                    self._logger.debug(\"writing dump to path %s\", self.dump_filename)\n                    allstr = InternalWorkerMessage(\n                        event_number=work_assignment.event_number,\n                        streams={k: v.get_bytes() for k, v in zmqparts.items()},\n                    )\n                    try:\n                        cbor2.dump(\n                            CBORTag(55799, allstr),\n                            self.dump_file,\n                            default=message_encoder,\n                        )\n                    except Exception as e:\n                        self._logger.error(\"cound not dump %s\", e.__repr__())\n                    self._logger.debug(\"written dump\")\n\n                workermessages: dict[WorkerName, InternalWorkerMessage] = {}\n                for stream, workers in work_assignment.assignments.items():\n                    for worker in workers:\n                        if worker not in workermessages:\n                            workermessages[worker] = InternalWorkerMessage(\n                                event_number=work_assignment.event_number\n                            )\n                        workermessages[worker].streams[stream] = zmqparts[stream]\n                self._logger.debug(\"workermessages %s\", workermessages)\n                await self._send_workermessages(workermessages)\n                end = time.perf_counter()\n                took.append(end - start)\n                if len(took) &gt; 1000:\n                    self._logger.info(\n                        \"forwarding took avg %lf, min %f max %f\",\n                        sum(took) / len(took),\n                        min(took),\n                        max(took),\n                    )\n                    self._logger.info(\"waiting for queue %d of 1000\", len(empties))\n                    took = []\n                    empties = []\n                self.state.processed_events += 1\n        except asyncio.exceptions.CancelledError:\n            self._logger.info(\"stopping worker\")\n            for stream in self.active_streams:\n                await self.stop_source(stream)\n            if self.dump_file:\n                self._logger.info(\n                    \"closing dump file %s at cancelled work\", self.dump_file\n                )\n                self.dump_file.close()\n                self.dump_file = None\n\n    async def run_source(\n        self, stream: StreamName\n    ) -&gt; AsyncGenerator[StreamData | IsSoftwareTriggered, None]:\n        \"\"\"\n        This generator must be implemented by the customised subclass. It should return exactly one `StreamData` object\n        for every frame arriving from upstream.\n\n        Arguments:\n            stream: optionally it received a stream name for which is should yield frames.\n\n        Returns:\n            Yield a StreamData object for every received frame.\n        \"\"\"\n        yield StreamData(typ=\"\", frames=[])\n        return\n\n    async def stop_source(self, stream: StreamName) -&gt; None:\n        pass\n\n    async def accept_workers(self) -&gt; None:\n        \"\"\"\n        To allow zmq to learn the names of attached workers, they periodically send empty packets.\n        There is no information flow directly from workers to ingesters, so we discard the data.\n        \"\"\"\n        poller = zmq.asyncio.Poller()\n        poller.register(self.out_socket, zmq.POLLIN)\n        while True:\n            socks = dict(await poller.poll(timeout=1))\n            # clean up old workers\n            now = time.time()\n            self.state.connected_workers = {\n                uuid: cw\n                for uuid, cw in self.state.connected_workers.items()\n                if now - cw.last_seen &lt; 4\n            }\n            for sock in socks:\n                data = await sock.recv_multipart()\n                connected_worker = ConnectedWorker(\n                    name=data[0], service_uuid=UUID(bytes=data[1])\n                )\n                fast_publish = False\n                if connected_worker.service_uuid not in self.state.connected_workers:\n                    fast_publish = True\n                self.state.connected_workers[\n                    connected_worker.service_uuid\n                ] = connected_worker\n                self._logger.debug(\"worker pinnged %s\", connected_worker)\n                if fast_publish:\n                    self._logger.debug(\"fast publish\")\n                    await self.publish_config()\n\n    async def close(self) -&gt; None:\n        \"\"\"\n        Clean up any open connections\n        \"\"\"\n        await cancel_and_wait(self.accept_task)\n        await cancel_and_wait(self.work_task)\n        await cancel_and_wait(self.metrics_task)\n        await cancel_and_wait(self.assign_task)\n        await self.redis.delete(RedisKeys.config(\"ingester\", self.state.name))\n        await super().close()\n        self.ctx.destroy(linger=0)\n        self._logger.info(\"closed ingester\")\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.accept_workers","title":"<code>accept_workers()</code>  <code>async</code>","text":"<p>To allow zmq to learn the names of attached workers, they periodically send empty packets. There is no information flow directly from workers to ingesters, so we discard the data.</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def accept_workers(self) -&gt; None:\n    \"\"\"\n    To allow zmq to learn the names of attached workers, they periodically send empty packets.\n    There is no information flow directly from workers to ingesters, so we discard the data.\n    \"\"\"\n    poller = zmq.asyncio.Poller()\n    poller.register(self.out_socket, zmq.POLLIN)\n    while True:\n        socks = dict(await poller.poll(timeout=1))\n        # clean up old workers\n        now = time.time()\n        self.state.connected_workers = {\n            uuid: cw\n            for uuid, cw in self.state.connected_workers.items()\n            if now - cw.last_seen &lt; 4\n        }\n        for sock in socks:\n            data = await sock.recv_multipart()\n            connected_worker = ConnectedWorker(\n                name=data[0], service_uuid=UUID(bytes=data[1])\n            )\n            fast_publish = False\n            if connected_worker.service_uuid not in self.state.connected_workers:\n                fast_publish = True\n            self.state.connected_workers[\n                connected_worker.service_uuid\n            ] = connected_worker\n            self._logger.debug(\"worker pinnged %s\", connected_worker)\n            if fast_publish:\n                self._logger.debug(\"fast publish\")\n                await self.publish_config()\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.close","title":"<code>close()</code>  <code>async</code>","text":"<p>Clean up any open connections</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"\n    Clean up any open connections\n    \"\"\"\n    await cancel_and_wait(self.accept_task)\n    await cancel_and_wait(self.work_task)\n    await cancel_and_wait(self.metrics_task)\n    await cancel_and_wait(self.assign_task)\n    await self.redis.delete(RedisKeys.config(\"ingester\", self.state.name))\n    await super().close()\n    self.ctx.destroy(linger=0)\n    self._logger.info(\"closed ingester\")\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.finish_work","title":"<code>finish_work()</code>  <code>async</code>","text":"<p>This hook is called when all events of a trigger map were ingested. It is useful for e.g. closing open files.</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def finish_work(self) -&gt; None:\n    \"\"\"\n    This hook is called when all events of a trigger map were ingested. It is useful for e.g. closing open files.\n    \"\"\"\n    self._logger.info(\"finishing work\")\n    if self.dump_file:\n        self.dump_file.close()\n        self._logger.info(\"closed dump file at finish %s\", self.dump_file)\n        self.dump_file = None\n\n    await self.redis.xadd(\n        RedisKeys.ready(self.state.mapping_uuid),\n        {\n            \"data\": IngesterUpdate(\n                state=DistributedStateEnum.FINISHED,\n                ingester=self.state.name,\n            ).model_dump_json()\n        },\n    )\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.manage_assignments","title":"<code>manage_assignments()</code>  <code>async</code>","text":"<p>A background task reading assignments from the controller, filering them for the relevant ones and enqueueing them for when the frame arrives.</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def manage_assignments(self) -&gt; None:\n    \"\"\"\n    A background task reading assignments from the controller, filering them for the relevant ones and enqueueing them for when the frame arrives.\n    \"\"\"\n    self._logger.info(\"started ingester manage assign task\")\n    lastev = 0\n    while True:\n        sub = RedisKeys.assigned(self.state.mapping_uuid)\n        try:\n            assignments = await self.redis.xread({sub: lastev}, block=1000)\n        except rexceptions.ConnectionError:\n            break\n        if sub not in assignments:\n            continue\n        assignment_evs = assignments[sub][0]\n        self._logger.debug(\"got assignments %s\", assignment_evs)\n        for assignment in assignment_evs:\n            was = WorkAssignmentList.validate_json(assignment[1][\"data\"])\n            for wa in was:\n                mywa = wa.get_workers_for_streams(self.active_streams)\n                if len(mywa.assignments) &gt; 0:\n                    await self.assignment_queue.put(mywa)\n            lastev = assignment[0]\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.restart_work","title":"<code>restart_work(new_uuid, active_streams)</code>  <code>async</code>","text":"<p>Restarts all work related tasks to make sure no old state is present in a new scan.</p> <p>Parameters:</p> Name Type Description Default <code>new_uuid</code> <code>UUID4</code> <p>The uuid of the new mapping</p> required Source code in <code>dranspose/ingester.py</code> <pre><code>async def restart_work(\n    self, new_uuid: UUID4, active_streams: list[StreamName]\n) -&gt; None:\n    \"\"\"\n    Restarts all work related tasks to make sure no old state is present in a new scan.\n\n    Arguments:\n        new_uuid: The uuid of the new mapping\n    \"\"\"\n    await cancel_and_wait(self.work_task)\n    await cancel_and_wait(self.assign_task)\n    self.state.mapping_uuid = new_uuid\n    self.active_streams = list(set(active_streams).intersection(self.state.streams))\n    self.assignment_queue = asyncio.Queue()\n    self.work_task = asyncio.create_task(self.work())\n    self.work_task.add_done_callback(done_callback)\n    self.assign_task = asyncio.create_task(self.manage_assignments())\n    self.assign_task.add_done_callback(done_callback)\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Main function orchestrating the dependent tasks. This needs to be called from an async context once an instance is created.</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def run(self) -&gt; None:\n    \"\"\"\n    Main function orchestrating the dependent tasks. This needs to be called from an async context once an instance is created.\n    \"\"\"\n    try:\n        self.open_socket()\n    except Exception as e:\n        self._logger.error(\n            \"unable to open inward facing router socket %s\", e.__repr__()\n        )\n\n    self.accept_task = asyncio.create_task(self.accept_workers())\n    self.accept_task.add_done_callback(done_callback)\n    self.work_task = asyncio.create_task(self.work())\n    self.work_task.add_done_callback(done_callback)\n    self.assign_task = asyncio.create_task(self.manage_assignments())\n    self.assign_task.add_done_callback(done_callback)\n    self.assignment_queue: asyncio.Queue[WorkAssignment] = asyncio.Queue()\n    self.metrics_task = asyncio.create_task(self.update_metrics())\n    self.metrics_task.add_done_callback(done_callback)\n    self._logger.info(\"all subtasks running\")\n    await self.register()\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.run_source","title":"<code>run_source(stream)</code>  <code>async</code>","text":"<p>This generator must be implemented by the customised subclass. It should return exactly one <code>StreamData</code> object for every frame arriving from upstream.</p> <p>Parameters:</p> Name Type Description Default <code>stream</code> <code>StreamName</code> <p>optionally it received a stream name for which is should yield frames.</p> required <p>Returns:</p> Type Description <code>AsyncGenerator[StreamData | IsSoftwareTriggered, None]</code> <p>Yield a StreamData object for every received frame.</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def run_source(\n    self, stream: StreamName\n) -&gt; AsyncGenerator[StreamData | IsSoftwareTriggered, None]:\n    \"\"\"\n    This generator must be implemented by the customised subclass. It should return exactly one `StreamData` object\n    for every frame arriving from upstream.\n\n    Arguments:\n        stream: optionally it received a stream name for which is should yield frames.\n\n    Returns:\n        Yield a StreamData object for every received frame.\n    \"\"\"\n    yield StreamData(typ=\"\", frames=[])\n    return\n</code></pre>"},{"location":"reference/internals/ingester/#dranspose.ingester.Ingester.work","title":"<code>work()</code>  <code>async</code>","text":"<p>The heavy liftig function of an ingester. It consumes a generator <code>run_source()</code> which should be implemented for a specific protocol. It then assembles all streams for this ingester and forwards them to the assigned workers.</p> <p>Optionally the worker dumps the internal messages to disk. This is useful to develop workers with actual data captured.</p> Source code in <code>dranspose/ingester.py</code> <pre><code>async def work(self) -&gt; None:\n    \"\"\"\n    The heavy liftig function of an ingester. It consumes a generator `run_source()` which\n    should be implemented for a specific protocol.\n    It then assembles all streams for this ingester and forwards them to the assigned workers.\n\n    Optionally the worker dumps the internal messages to disk. This is useful to develop workers with actual data captured.\n    \"\"\"\n    self._logger.info(\"started ingester work task\")\n    sourcegens = {stream: self.run_source(stream) for stream in self.active_streams}\n    if len(sourcegens) == 0:\n        self._logger.warning(\"this ingester has no active streams, stopping worker\")\n        return\n    swtriggen: Iterator[dict[StreamName, StreamData]] | None = None\n    if hasattr(self, \"software_trigger\"):\n        swtriggen = self.software_trigger()\n    self.dump_file = None\n    self.dump_filename = self._ingester_settings.dump_path\n    if self.dump_filename is None and \"dump_prefix\" in self.parameters:\n        val = self.parameters[ParameterName(\"dump_prefix\")].data.decode(\"utf8\")\n        if len(val) &gt; 0:\n            self.dump_filename = f\"{val}{self._ingester_settings.ingester_name}-{self.state.mapping_uuid}.cbors\"\n    if self.dump_filename:\n        self.dump_file = open(self.dump_filename, \"ab\")\n        self._logger.info(\n            \"dump file %s opened at %s\",\n            self.dump_filename,\n            self.dump_file,\n        )\n    try:\n        took = []\n        empties = []\n        while True:\n            empty = False\n            if self.assignment_queue.empty():\n                empty = True\n            start = time.perf_counter()\n            work_assignment: WorkAssignment = await self.assignment_queue.get()\n            if empty:\n                empties.append(work_assignment.event_number)\n\n            zmqparts = await self._get_zmqparts(\n                work_assignment, sourcegens, swtriggen\n            )\n\n            if self.dump_file:\n                self._logger.debug(\"writing dump to path %s\", self.dump_filename)\n                allstr = InternalWorkerMessage(\n                    event_number=work_assignment.event_number,\n                    streams={k: v.get_bytes() for k, v in zmqparts.items()},\n                )\n                try:\n                    cbor2.dump(\n                        CBORTag(55799, allstr),\n                        self.dump_file,\n                        default=message_encoder,\n                    )\n                except Exception as e:\n                    self._logger.error(\"cound not dump %s\", e.__repr__())\n                self._logger.debug(\"written dump\")\n\n            workermessages: dict[WorkerName, InternalWorkerMessage] = {}\n            for stream, workers in work_assignment.assignments.items():\n                for worker in workers:\n                    if worker not in workermessages:\n                        workermessages[worker] = InternalWorkerMessage(\n                            event_number=work_assignment.event_number\n                        )\n                    workermessages[worker].streams[stream] = zmqparts[stream]\n            self._logger.debug(\"workermessages %s\", workermessages)\n            await self._send_workermessages(workermessages)\n            end = time.perf_counter()\n            took.append(end - start)\n            if len(took) &gt; 1000:\n                self._logger.info(\n                    \"forwarding took avg %lf, min %f max %f\",\n                    sum(took) / len(took),\n                    min(took),\n                    max(took),\n                )\n                self._logger.info(\"waiting for queue %d of 1000\", len(empties))\n                took = []\n                empties = []\n            self.state.processed_events += 1\n    except asyncio.exceptions.CancelledError:\n        self._logger.info(\"stopping worker\")\n        for stream in self.active_streams:\n            await self.stop_source(stream)\n        if self.dump_file:\n            self._logger.info(\n                \"closing dump file %s at cancelled work\", self.dump_file\n            )\n            self.dump_file.close()\n            self.dump_file = None\n</code></pre>"},{"location":"reference/internals/reducer/","title":"Reducer","text":""},{"location":"reference/internals/reducer/#sequence-diagram","title":"Sequence Diagram","text":"<p>The reducer is quite simple as it has a <code>work</code> task and a <code>timer</code> task for periodic callbacks. Both get restarted on <code>restart_work</code> and the <code>update</code> metrics and <code>register</code> run until the end.</p> <pre><code>sequenceDiagram\n    Reducer -&gt;&gt;+ work: run\n    Reducer -&gt;&gt;+ timer: run\n    Reducer -&gt;&gt;+ update_metrics: run\n    Reducer -&gt;&gt;+ register: run\n\n\n    timer -&gt;&gt;- Reducer: restart work\n    work -&gt;&gt;- Reducer: restart work\n    Reducer -&gt;&gt;+ work: restart work\n    Reducer -&gt;&gt;+ timer: restart work\n\n    timer -&gt;&gt;- Reducer: close\n    work -&gt;&gt;- Reducer: close\n    update_metrics -&gt;&gt;- Reducer: close\n\n\n</code></pre>"},{"location":"reference/internals/worker/","title":"Worker","text":""},{"location":"reference/internals/worker/#sequence-diagram","title":"Sequence Diagram","text":"<p>The worker runs many concurrent coroutines to achieve all its tasks.</p> <p>On <code>run</code> it starts most of the coroutines. <code>restart_work</code> first cancels the work relevant ones and then restarts them cleanly. The <code>work</code> coroutine itself uses a <code>dequeue</code> and <code>poll</code> coroutine to explicitly wait for new assignments or data from ingesters. This is required to achieve a clean <code>restart_work</code> and cancel this waiting. <code>close</code> cleans up all open coroutines.</p> <pre><code>sequenceDiagram\n    Worker -&gt;&gt;+ manage_ingesters: run\n    Worker -&gt;&gt;+ manage_receiver: run\n    Worker -&gt;&gt;+ work: run\n    Worker -&gt;&gt;+ manage_assignments: run\n    Worker -&gt;&gt;+ update_metrics: run\n    Worker -&gt;&gt;+ register: run\n\n    work -&gt;&gt;+ dequeue: wait for new ingesterset\n    dequeue -&gt;&gt;- work: set available\n\n    work -&gt;&gt;+ poll: poll ingesters\n    poll -&gt;&gt;- work: gathered all ingester\n\n    poll -&gt;&gt; Worker: restart work\n    work -&gt;&gt;- Worker: restart work\n    manage_assignments -&gt;&gt;- Worker: restart work\n    Worker -&gt;&gt;+ work: restart work\n    Worker -&gt;&gt;+ manage_assignments: restart work\n\n    manage_ingesters -&gt;&gt;- Worker: close\n    manage_receiver -&gt;&gt;- Worker: close\n    update_metrics -&gt;&gt;- Worker: close\n    manage_assignments -&gt;&gt;- Worker: close\n    dequeue -&gt;&gt; Worker: close\n\n\n</code></pre>"},{"location":"reference/internals/worker/#worker-ingester-ping-sequence","title":"Worker Ingester Ping Sequence","text":"<pre><code>sequenceDiagram\n    Worker -&gt;&gt; Ingester: ping with uuid\n    Ingester -&gt;&gt; Redis: update connected workers\n\n    Redis -&gt;&gt; Worker: fetch ingester state with connected workers\n\n    Worker -&gt;&gt; Worker: Check if pings reached Ingester\n\n\n</code></pre>"},{"location":"reference/internals/worker/#dranspose.worker.ConnectedIngester","title":"<code>ConnectedIngester</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>An ingester becomes a connected ingester once the worker opened a socket to it</p> Source code in <code>dranspose/worker.py</code> <pre><code>class ConnectedIngester(BaseModel):\n    \"An ingester becomes a connected ingester once the worker opened a socket to it\"\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    socket: zmq.asyncio.Socket\n    config: IngesterState\n    pinged_since: float = Field(default_factory=time.time)\n</code></pre>"},{"location":"reference/internals/worker/#dranspose.worker.Worker","title":"<code>Worker</code>","text":"<p>               Bases: <code>DistributedService</code></p> Source code in <code>dranspose/worker.py</code> <pre><code>class Worker(DistributedService):\n    def __init__(self, settings: Optional[WorkerSettings] = None):\n        self._worker_settings = settings\n        if self._worker_settings is None:\n            self._worker_settings = WorkerSettings()\n\n        state = WorkerState(\n            name=self._worker_settings.worker_name,\n            tags=self._worker_settings.worker_tags,\n        )\n        super().__init__(state, self._worker_settings)\n        self._logger.info(\"created worker with state %s\", state)\n        self.state: WorkerState\n        self.ctx = zmq.asyncio.Context()\n\n        self._ingesters: dict[IngesterName, ConnectedIngester] = {}\n        self._stream_map: dict[StreamName, zmq._future._AsyncSocket] = {}\n        self.poll_task: Optional[Future[list[int]]] = None\n\n        self._reducer_service_uuid: Optional[UUID4] = None\n        self.out_socket: Optional[zmq._future._AsyncSocket] = None\n\n        self.assignment_queue: asyncio.Queue[\n            set[zmq._future._AsyncSocket]\n        ] = asyncio.Queue()\n        self.dequeue_task: Optional[Task[set[zmq._future._AsyncSocket]]] = None\n\n        self.param_descriptions = []\n        self.custom = None\n        self.custom_context: dict[Any, Any] = {}\n        self.worker = None\n        if self._worker_settings.worker_class:\n            try:\n                self.custom = utils.import_class(self._worker_settings.worker_class)\n                self._logger.info(\"custom worker class %s\", self.custom)\n\n                try:\n                    self.param_descriptions = self.custom.describe_parameters()  # type: ignore[attr-defined]\n                except AttributeError:\n                    self._logger.info(\n                        \"custom worker class has no describe_parameters staticmethod\"\n                    )\n                except Exception as e:\n                    self._logger.error(\n                        \"custom worker parameter descripition is broken: %s\",\n                        e.__repr__(),\n                    )\n\n            except Exception as e:\n                self._logger.error(\n                    \"no custom worker class loaded, discarding events, err %s\\n%s\",\n                    e.__repr__(),\n                    traceback.format_exc(),\n                )\n\n    async def run(self) -&gt; None:\n        self.manage_ingester_task = asyncio.create_task(self.manage_ingesters())\n        self.manage_ingester_task.add_done_callback(done_callback)\n        self.manage_receiver_task = asyncio.create_task(self.manage_receiver())\n        self.manage_receiver_task.add_done_callback(done_callback)\n        self.assignment_queue = asyncio.Queue()\n        self.work_task = asyncio.create_task(self.work())\n        self.work_task.add_done_callback(done_callback)\n        self.assign_task = asyncio.create_task(self.manage_assignments())\n        self.assign_task.add_done_callback(done_callback)\n        self.metrics_task = asyncio.create_task(self.update_metrics())\n        self.metrics_task.add_done_callback(done_callback)\n        await self.register()\n\n    async def notify_worker_ready(self) -&gt; None:\n        \"send an update to the controller that the worker got the new trigger map and is ready to receive the first event\"\n        await self.redis.xadd(\n            RedisKeys.ready(self.state.mapping_uuid),\n            {\n                \"data\": WorkerUpdate(\n                    state=DistributedStateEnum.READY,\n                    worker=self.state.name,\n                ).model_dump_json()\n            },\n        )\n\n        self._logger.info(\"registered ready message\")\n\n    async def manage_assignments(self) -&gt; None:\n        \"\"\"\n        This coroutine listens to the redis stream for the current mapping_uuid.\n        Once it there is a new batch of assignments, it checks for each,\n        if this worker is involved and if yes, from which ingesters it should receive.\n        It places the list of ingesters in the assignment_queue.\n        \"\"\"\n        sub = RedisKeys.assigned(self.state.mapping_uuid)\n        lastev = 0\n        while True:\n            try:\n                assignments = await self.redis.xread({sub: lastev}, block=1000, count=1)\n            except rexceptions.ConnectionError:\n                break\n            if sub not in assignments:\n                continue\n            assignments = assignments[sub][0][0]\n            self._logger.debug(\"got assignments %s\", assignments)\n            self._logger.debug(\"stream map %s\", self._stream_map)\n            work_assignment_list = WorkAssignmentList.validate_json(\n                assignments[1][\"data\"]\n            )\n            for work_assignment in work_assignment_list:\n                ingesterset = set()\n                for stream, workers in work_assignment.assignments.items():\n                    if self.state.name in workers:\n                        try:\n                            ingesterset.add(self._stream_map[stream])\n                        except KeyError:\n                            self._logger.error(\n                                \"ingester for stream %s not connected, available: %s\",\n                                stream,\n                                self._ingesters,\n                            )\n                self._logger.debug(\"receive from ingesters %s\", ingesterset)\n                if len(ingesterset) &gt; 0:\n                    await self.assignment_queue.put(ingesterset)\n            lastev = assignments[0]\n\n    async def poll_internals(\n        self, ingesterset: set[zmq._future._AsyncSocket]\n    ) -&gt; list[int]:\n        \"\"\"\n        A task to simultaneously check if there is a message available from all required ingesters\n        We do not yet receive from the zmq sockets as it is harder to cancel a receive call.\n        \"\"\"\n        self._logger.debug(\"poll internal sockets %s\", ingesterset)\n        poll_tasks = [sock.poll() for sock in ingesterset]\n        self._logger.debug(\"await poll tasks %s\", poll_tasks)\n        self.poll_task = asyncio.gather(*poll_tasks)\n        done = await self.poll_task\n        self._logger.debug(\"data is available done: %s\", done)\n        return done\n\n    async def build_event(\n        self, ingesterset: set[zmq._future._AsyncSocket]\n    ) -&gt; EventData:\n        \"All relevant ingester sockets have a message, receive it and assemble an EventData object\"\n        msgs = []\n        for sock in ingesterset:\n            res = await sock.recv_multipart(copy=False)\n            prelim = json.loads(res[0].bytes)\n            pos = 1\n            for stream, data in prelim[\"streams\"].items():\n                data[\"frames\"] = res[pos : pos + data[\"length\"]]\n                pos += data[\"length\"]\n            msg = InternalWorkerMessage.model_validate(prelim)\n            msgs.append(msg)\n\n        return EventData.from_internals(msgs)\n\n    async def work(self) -&gt; None:\n        self._logger.info(\"started work task\")\n\n        self.worker = None\n        if self.custom:\n            try:\n                self.worker = self.custom(\n                    parameters=self.parameters,\n                    context=self.custom_context,\n                    state=self.state,\n                )\n            except Exception as e:\n                self._logger.error(\n                    \"Failed to instantiate custom worker: %s\", e.__repr__()\n                )\n\n        await self.notify_worker_ready()\n        try:\n            proced = 0\n            completed = []\n            has_result = []\n            accum_times = WorkerTimes(no_events=0)\n            accum_start = time.time()\n            tick_wait_until = time.time() - 1\n            while True:\n                perf_start = time.perf_counter()\n\n                self.dequeue_task = None\n                self.dequeue_task = asyncio.create_task(self.assignment_queue.get())\n                ingesterset = await self.dequeue_task\n                perf_got_assignments = time.perf_counter()\n                done = await self.poll_internals(ingesterset)\n                if set(done) != {zmq.POLLIN}:\n                    self._logger.warning(\"not all sockets are pollIN %s\", done)\n                    continue\n\n                perf_got_work = time.perf_counter()\n\n                event = await self.build_event(ingesterset)\n\n                perf_assembled_event = time.perf_counter()\n                self._logger.debug(\"received work %s\", event)\n                result = None\n                if self.worker:\n                    tick = False\n                    # we internally cache when the redis will expire to reduce hitting redis on every event\n                    if tick_wait_until - time.time() &lt; 0:\n                        if hasattr(self.worker, \"get_tick_interval\"):\n                            wait_ms = int(\n                                self.worker.get_tick_interval(self.parameters) * 1000\n                            )\n                            dist_clock = await self.redis.set(\n                                RedisKeys.clock(self.state.mapping_uuid),\n                                \"\ud83d\udd59\",\n                                px=wait_ms,\n                                nx=True,\n                            )\n                            if dist_clock is True:\n                                tick = True\n                            else:\n                                expire_ms = await self.redis.pttl(\n                                    RedisKeys.clock(self.state.mapping_uuid)\n                                )\n                                tick_wait_until = time.time() + (expire_ms / 1000)\n                    try:\n                        loop = asyncio.get_event_loop()\n                        result = await loop.run_in_executor(\n                            None,\n                            self.worker.process_event,\n                            event,\n                            self.parameters,\n                            tick,\n                        )\n                    except Exception as e:\n                        self._logger.error(\n                            \"custom worker failed: %s\\n%s\",\n                            e.__repr__(),\n                            traceback.format_exc(),\n                        )\n                perf_custom_code = time.perf_counter()\n                self._logger.debug(\"got result %s\", result)\n                if result is not None:\n                    rd = ResultData(\n                        event_number=event.event_number,\n                        worker=self.state.name,\n                        payload=result,\n                        parameters_hash=self.state.parameters_hash,\n                    )\n                    if self.out_socket:\n                        try:\n                            header = rd.model_dump_json(exclude={\"payload\"}).encode(\n                                \"utf8\"\n                            )\n                            body = pickle.dumps(rd.payload)\n                            self._logger.debug(\n                                \"send result to reducer with header %s, len-payload %d\",\n                                header,\n                                len(body),\n                            )\n                            await self.out_socket.send_multipart([header, body])\n                        except Exception as e:\n                            self._logger.error(\n                                \"could not send out result %s\", e.__repr__()\n                            )\n                perf_sent_result = time.perf_counter()\n                proced += 1\n                self.state.processed_events += 1\n                if proced % 500 == 0:\n                    self._logger.info(\"processed %d events\", proced)\n                completed.append(event.event_number)\n                has_result.append(result is not None)\n                times = WorkerTimes.from_timestamps(\n                    perf_start,\n                    perf_got_assignments,\n                    perf_got_work,\n                    perf_assembled_event,\n                    perf_custom_code,\n                    perf_sent_result,\n                )\n                accum_times += times\n                # the worker only sends an update to the controller if it is idle or a second has passed\n                # this batching is necessary for high frequency event streams\n                if self.assignment_queue.empty() or time.time() - accum_start &gt; 1:\n                    wu = WorkerUpdate(\n                        state=DistributedStateEnum.IDLE,\n                        completed=completed,\n                        worker=self.state.name,\n                        has_result=has_result,\n                        processing_times=accum_times,\n                    )\n                    self._logger.debug(\"all work done, notify controller with %s\", wu)\n                    await self.redis.xadd(\n                        RedisKeys.ready(self.state.mapping_uuid),\n                        {\"data\": wu.model_dump_json()},\n                    )\n                    completed = []\n                    has_result = []\n                    accum_times = WorkerTimes(no_events=0)\n                    accum_start = time.time()\n        except asyncio.exceptions.CancelledError:\n            pass\n        self._logger.info(\"work thread finished\")\n\n    async def finish_work(self) -&gt; None:\n        self._logger.info(\"finishing work\")\n        if self.worker:\n            if hasattr(self.worker, \"finish\"):\n                try:\n                    loop = asyncio.get_event_loop()\n                    await loop.run_in_executor(\n                        None, self.worker.finish, self.parameters\n                    )\n                except Exception as e:\n                    self._logger.error(\n                        \"custom worker finish failed: %s\\n%s\",\n                        e.__repr__(),\n                        traceback.format_exc(),\n                    )\n        await self.redis.xadd(\n            RedisKeys.ready(self.state.mapping_uuid),\n            {\n                \"data\": WorkerUpdate(\n                    state=DistributedStateEnum.FINISHED,\n                    worker=self.state.name,\n                ).model_dump_json()\n            },\n        )\n\n    async def restart_work(\n        self, new_uuid: UUID4, active_streams: list[StreamName]\n    ) -&gt; None:\n        self._logger.info(\"resetting config %s\", new_uuid)\n        if self.poll_task:\n            await cancel_and_wait(self.poll_task)\n            self.poll_task = None\n            self._logger.debug(\"cancelled poll task\")\n        await cancel_and_wait(self.work_task)\n        self._logger.info(\"clean up in sockets\")\n        await cancel_and_wait(self.assign_task)\n        for iname, ing in self._ingesters.items():\n            while True:\n                res = await ing.socket.poll(timeout=0.001)\n                if res == zmq.POLLIN:\n                    await ing.socket.recv_multipart(copy=False)\n                    self._logger.debug(\"discarded internal message from %s\", iname)\n                else:\n                    break\n\n        self.assignment_queue = asyncio.Queue()\n        self.state.mapping_uuid = new_uuid\n        self.work_task = asyncio.create_task(self.work())\n        self.work_task.add_done_callback(done_callback)\n        self.assign_task = asyncio.create_task(self.manage_assignments())\n        self.assign_task.add_done_callback(done_callback)\n\n    async def manage_receiver(self) -&gt; None:\n        \"Periodically check that the push socket to the receiver is connected to the correct url, which the reducer publishes in redis\"\n        while True:\n            config = await self.redis.get(RedisKeys.config(\"reducer\"))\n            if config is None:\n                self._logger.warning(\"cannot get reducer configuration\")\n                await asyncio.sleep(1)\n                continue\n            cfg = ReducerState.model_validate_json(config)\n            if cfg.service_uuid != self._reducer_service_uuid:\n                # connect to a new reducer\n                if self.out_socket is not None:\n                    self.out_socket.close()\n                self.out_socket = self.ctx.socket(zmq.PUSH)\n                self.out_socket.connect(str(cfg.url))\n                self._reducer_service_uuid = cfg.service_uuid\n                self._logger.info(\"connected out_socket to reducer at %s\", cfg.url)\n            await asyncio.sleep(10)\n\n    async def manage_ingesters(self) -&gt; None:\n        \"\"\"\n        This function is supposed to run in the background and make sure\n        that the worker has a DEALER socket to every ingester.\n        It periodically pings the ingesters and checks that the pings arrive\n        by fetching the state of the ingesters from redis.\n        \"\"\"\n        while True:\n            configs = await self.redis.keys(RedisKeys.config(\"ingester\"))\n            processed = []\n            for key in configs:\n                raw_config = await self.redis.get(key)\n                if raw_config is None:\n                    logging.warning(\n                        \"ingester config key %s disappeard while updating\", key\n                    )\n                    continue\n                cfg = IngesterState.model_validate_json(raw_config)\n                iname = cfg.name\n                processed.append(iname)\n                if iname in self._ingesters:\n                    pinged_for_long = (\n                        time.time() - self._ingesters[iname].pinged_since &gt; 10\n                    )\n                    reached_ingester = (\n                        self.state.service_uuid in cfg.connected_workers.keys()\n                    )\n\n                    if self._ingesters[iname].config.service_uuid != cfg.service_uuid:\n                        self._logger.warning(\n                            \"service_uuid of ingester changed from %s to %s, disconnecting\",\n                            self._ingesters[iname].config.service_uuid,\n                            cfg.service_uuid,\n                        )\n                        self._ingesters[iname].socket.close()\n                        del self._ingesters[iname]\n\n                    elif pinged_for_long and not reached_ingester:\n                        self._logger.warning(\n                            \"we send pings, but don't reach ingester %s, disconnecting\",\n                            iname,\n                        )\n                        self._ingesters[iname].socket.close()\n                        del self._ingesters[iname]\n\n                if iname not in self._ingesters:\n                    self._logger.info(\"adding new ingester %s\", iname)\n                    try:\n                        sock = self.ctx.socket(zmq.DEALER)\n                        sock.setsockopt(zmq.IDENTITY, self.state.name.encode(\"ascii\"))\n                        sock.connect(str(cfg.url))\n                        await sock.send(self.state.service_uuid.bytes)\n                        self._ingesters[iname] = ConnectedIngester(\n                            config=cfg, socket=sock\n                        )\n                    except zmq.error.ZMQError:\n                        logging.error(\"cannot open dealer socket to ingester %s\", iname)\n\n                await self._ingesters[iname].socket.send(self.state.service_uuid.bytes)\n                self._logger.debug(\"pinged %s\", iname)\n            for iname in set(self._ingesters.keys()) - set(processed):\n                self._logger.info(\"removing stale ingester %s\", iname)\n                self._ingesters[iname].socket.close()\n                del self._ingesters[iname]\n            self._stream_map = {\n                s: conn_ing.socket\n                for ing, conn_ing in self._ingesters.items()\n                for s in conn_ing.config.streams\n            }\n            new_ingesters = [a.config for a in self._ingesters.values()]\n            if self.state.ingesters != new_ingesters:\n                self.state.ingesters = new_ingesters\n                self._logger.info(\n                    \"changed ingester config, fast publish %s\", new_ingesters\n                )\n                await self.publish_config()\n\n            await asyncio.sleep(2)\n\n    async def close(self) -&gt; None:\n        if self.worker:\n            if hasattr(self.worker, \"close\"):\n                try:\n                    loop = asyncio.get_event_loop()\n                    await loop.run_in_executor(\n                        None, self.worker.close, self.custom_context\n                    )\n                except Exception as e:\n                    self._logger.error(\n                        \"custom worker failed to close: %s\\n%s\",\n                        e.__repr__(),\n                        traceback.format_exc(),\n                    )\n        await cancel_and_wait(self.manage_ingester_task)\n        await cancel_and_wait(self.manage_receiver_task)\n        await cancel_and_wait(self.metrics_task)\n        await cancel_and_wait(self.assign_task)\n        if self.dequeue_task is not None:\n            await cancel_and_wait(self.dequeue_task)\n        await self.redis.delete(RedisKeys.config(\"worker\", self.state.name))\n        await super().close()\n        self.ctx.destroy()\n        self._logger.info(\"worker closed\")\n</code></pre>"},{"location":"reference/internals/worker/#dranspose.worker.Worker.build_event","title":"<code>build_event(ingesterset)</code>  <code>async</code>","text":"<p>All relevant ingester sockets have a message, receive it and assemble an EventData object</p> Source code in <code>dranspose/worker.py</code> <pre><code>async def build_event(\n    self, ingesterset: set[zmq._future._AsyncSocket]\n) -&gt; EventData:\n    \"All relevant ingester sockets have a message, receive it and assemble an EventData object\"\n    msgs = []\n    for sock in ingesterset:\n        res = await sock.recv_multipart(copy=False)\n        prelim = json.loads(res[0].bytes)\n        pos = 1\n        for stream, data in prelim[\"streams\"].items():\n            data[\"frames\"] = res[pos : pos + data[\"length\"]]\n            pos += data[\"length\"]\n        msg = InternalWorkerMessage.model_validate(prelim)\n        msgs.append(msg)\n\n    return EventData.from_internals(msgs)\n</code></pre>"},{"location":"reference/internals/worker/#dranspose.worker.Worker.manage_assignments","title":"<code>manage_assignments()</code>  <code>async</code>","text":"<p>This coroutine listens to the redis stream for the current mapping_uuid. Once it there is a new batch of assignments, it checks for each, if this worker is involved and if yes, from which ingesters it should receive. It places the list of ingesters in the assignment_queue.</p> Source code in <code>dranspose/worker.py</code> <pre><code>async def manage_assignments(self) -&gt; None:\n    \"\"\"\n    This coroutine listens to the redis stream for the current mapping_uuid.\n    Once it there is a new batch of assignments, it checks for each,\n    if this worker is involved and if yes, from which ingesters it should receive.\n    It places the list of ingesters in the assignment_queue.\n    \"\"\"\n    sub = RedisKeys.assigned(self.state.mapping_uuid)\n    lastev = 0\n    while True:\n        try:\n            assignments = await self.redis.xread({sub: lastev}, block=1000, count=1)\n        except rexceptions.ConnectionError:\n            break\n        if sub not in assignments:\n            continue\n        assignments = assignments[sub][0][0]\n        self._logger.debug(\"got assignments %s\", assignments)\n        self._logger.debug(\"stream map %s\", self._stream_map)\n        work_assignment_list = WorkAssignmentList.validate_json(\n            assignments[1][\"data\"]\n        )\n        for work_assignment in work_assignment_list:\n            ingesterset = set()\n            for stream, workers in work_assignment.assignments.items():\n                if self.state.name in workers:\n                    try:\n                        ingesterset.add(self._stream_map[stream])\n                    except KeyError:\n                        self._logger.error(\n                            \"ingester for stream %s not connected, available: %s\",\n                            stream,\n                            self._ingesters,\n                        )\n            self._logger.debug(\"receive from ingesters %s\", ingesterset)\n            if len(ingesterset) &gt; 0:\n                await self.assignment_queue.put(ingesterset)\n        lastev = assignments[0]\n</code></pre>"},{"location":"reference/internals/worker/#dranspose.worker.Worker.manage_ingesters","title":"<code>manage_ingesters()</code>  <code>async</code>","text":"<p>This function is supposed to run in the background and make sure that the worker has a DEALER socket to every ingester. It periodically pings the ingesters and checks that the pings arrive by fetching the state of the ingesters from redis.</p> Source code in <code>dranspose/worker.py</code> <pre><code>async def manage_ingesters(self) -&gt; None:\n    \"\"\"\n    This function is supposed to run in the background and make sure\n    that the worker has a DEALER socket to every ingester.\n    It periodically pings the ingesters and checks that the pings arrive\n    by fetching the state of the ingesters from redis.\n    \"\"\"\n    while True:\n        configs = await self.redis.keys(RedisKeys.config(\"ingester\"))\n        processed = []\n        for key in configs:\n            raw_config = await self.redis.get(key)\n            if raw_config is None:\n                logging.warning(\n                    \"ingester config key %s disappeard while updating\", key\n                )\n                continue\n            cfg = IngesterState.model_validate_json(raw_config)\n            iname = cfg.name\n            processed.append(iname)\n            if iname in self._ingesters:\n                pinged_for_long = (\n                    time.time() - self._ingesters[iname].pinged_since &gt; 10\n                )\n                reached_ingester = (\n                    self.state.service_uuid in cfg.connected_workers.keys()\n                )\n\n                if self._ingesters[iname].config.service_uuid != cfg.service_uuid:\n                    self._logger.warning(\n                        \"service_uuid of ingester changed from %s to %s, disconnecting\",\n                        self._ingesters[iname].config.service_uuid,\n                        cfg.service_uuid,\n                    )\n                    self._ingesters[iname].socket.close()\n                    del self._ingesters[iname]\n\n                elif pinged_for_long and not reached_ingester:\n                    self._logger.warning(\n                        \"we send pings, but don't reach ingester %s, disconnecting\",\n                        iname,\n                    )\n                    self._ingesters[iname].socket.close()\n                    del self._ingesters[iname]\n\n            if iname not in self._ingesters:\n                self._logger.info(\"adding new ingester %s\", iname)\n                try:\n                    sock = self.ctx.socket(zmq.DEALER)\n                    sock.setsockopt(zmq.IDENTITY, self.state.name.encode(\"ascii\"))\n                    sock.connect(str(cfg.url))\n                    await sock.send(self.state.service_uuid.bytes)\n                    self._ingesters[iname] = ConnectedIngester(\n                        config=cfg, socket=sock\n                    )\n                except zmq.error.ZMQError:\n                    logging.error(\"cannot open dealer socket to ingester %s\", iname)\n\n            await self._ingesters[iname].socket.send(self.state.service_uuid.bytes)\n            self._logger.debug(\"pinged %s\", iname)\n        for iname in set(self._ingesters.keys()) - set(processed):\n            self._logger.info(\"removing stale ingester %s\", iname)\n            self._ingesters[iname].socket.close()\n            del self._ingesters[iname]\n        self._stream_map = {\n            s: conn_ing.socket\n            for ing, conn_ing in self._ingesters.items()\n            for s in conn_ing.config.streams\n        }\n        new_ingesters = [a.config for a in self._ingesters.values()]\n        if self.state.ingesters != new_ingesters:\n            self.state.ingesters = new_ingesters\n            self._logger.info(\n                \"changed ingester config, fast publish %s\", new_ingesters\n            )\n            await self.publish_config()\n\n        await asyncio.sleep(2)\n</code></pre>"},{"location":"reference/internals/worker/#dranspose.worker.Worker.manage_receiver","title":"<code>manage_receiver()</code>  <code>async</code>","text":"<p>Periodically check that the push socket to the receiver is connected to the correct url, which the reducer publishes in redis</p> Source code in <code>dranspose/worker.py</code> <pre><code>async def manage_receiver(self) -&gt; None:\n    \"Periodically check that the push socket to the receiver is connected to the correct url, which the reducer publishes in redis\"\n    while True:\n        config = await self.redis.get(RedisKeys.config(\"reducer\"))\n        if config is None:\n            self._logger.warning(\"cannot get reducer configuration\")\n            await asyncio.sleep(1)\n            continue\n        cfg = ReducerState.model_validate_json(config)\n        if cfg.service_uuid != self._reducer_service_uuid:\n            # connect to a new reducer\n            if self.out_socket is not None:\n                self.out_socket.close()\n            self.out_socket = self.ctx.socket(zmq.PUSH)\n            self.out_socket.connect(str(cfg.url))\n            self._reducer_service_uuid = cfg.service_uuid\n            self._logger.info(\"connected out_socket to reducer at %s\", cfg.url)\n        await asyncio.sleep(10)\n</code></pre>"},{"location":"reference/internals/worker/#dranspose.worker.Worker.notify_worker_ready","title":"<code>notify_worker_ready()</code>  <code>async</code>","text":"<p>send an update to the controller that the worker got the new trigger map and is ready to receive the first event</p> Source code in <code>dranspose/worker.py</code> <pre><code>async def notify_worker_ready(self) -&gt; None:\n    \"send an update to the controller that the worker got the new trigger map and is ready to receive the first event\"\n    await self.redis.xadd(\n        RedisKeys.ready(self.state.mapping_uuid),\n        {\n            \"data\": WorkerUpdate(\n                state=DistributedStateEnum.READY,\n                worker=self.state.name,\n            ).model_dump_json()\n        },\n    )\n\n    self._logger.info(\"registered ready message\")\n</code></pre>"},{"location":"reference/internals/worker/#dranspose.worker.Worker.poll_internals","title":"<code>poll_internals(ingesterset)</code>  <code>async</code>","text":"<p>A task to simultaneously check if there is a message available from all required ingesters We do not yet receive from the zmq sockets as it is harder to cancel a receive call.</p> Source code in <code>dranspose/worker.py</code> <pre><code>async def poll_internals(\n    self, ingesterset: set[zmq._future._AsyncSocket]\n) -&gt; list[int]:\n    \"\"\"\n    A task to simultaneously check if there is a message available from all required ingesters\n    We do not yet receive from the zmq sockets as it is harder to cancel a receive call.\n    \"\"\"\n    self._logger.debug(\"poll internal sockets %s\", ingesterset)\n    poll_tasks = [sock.poll() for sock in ingesterset]\n    self._logger.debug(\"await poll tasks %s\", poll_tasks)\n    self.poll_task = asyncio.gather(*poll_tasks)\n    done = await self.poll_task\n    self._logger.debug(\"data is available done: %s\", done)\n    return done\n</code></pre>"},{"location":"reference/internals/worker/#dranspose.worker.random_worker_name","title":"<code>random_worker_name()</code>","text":"<p>without a given worker name, generate a random one</p> Source code in <code>dranspose/worker.py</code> <pre><code>def random_worker_name() -&gt; WorkerName:\n    \"without a given worker name, generate a random one\"\n    randid = \"\".join([random.choice(string.ascii_letters) for _ in range(10)])\n    name = \"Worker-{}-{}\".format(socket.gethostname(), randid)\n    return WorkerName(name)\n</code></pre>"},{"location":"reference/protocols/STINS/","title":"STINS","text":""},{"location":"reference/protocols/STINS/#dranspose.data.stream1.Stream1Packet","title":"<code>Stream1Packet = TypeAdapter(Stream1Start | Stream1Data | Stream1End)</code>  <code>module-attribute</code>","text":"<p>A union type for STINS packets</p>"},{"location":"reference/protocols/STINS/#dranspose.data.stream1.Stream1Data","title":"<code>Stream1Data</code>","text":"<p>               Bases: <code>Stream1</code></p> Example <pre><code>Stream1Data(\n    msg_number=375,\n    htype='image',\n    frame=0,\n    shape=[831, 1475],\n    type='float32',\n    compression='none',\n    data=array([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)\n)\n</code></pre> Source code in <code>dranspose/data/stream1.py</code> <pre><code>class Stream1Data(Stream1):\n    \"\"\"\n    Example:\n        ``` py\n        Stream1Data(\n            msg_number=375,\n            htype='image',\n            frame=0,\n            shape=[831, 1475],\n            type='float32',\n            compression='none',\n            data=array([[0., 0., 0., ..., 0., 0., 0.],\n                [0., 0., 0., ..., 0., 0., 0.],\n                [0., 0., 0., ..., 0., 0., 0.],\n                ...,\n                [0., 0., 0., ..., 0., 0., 0.],\n                [0., 0., 0., ..., 0., 0., 0.],\n                [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    htype: Literal[\"image\"] = \"image\"\n    frame: int\n    shape: list[int]\n    type: str\n    compression: str\n</code></pre>"},{"location":"reference/protocols/STINS/#dranspose.data.stream1.Stream1End","title":"<code>Stream1End</code>","text":"<p>               Bases: <code>Stream1</code></p> Example <pre><code>Stream1End(\n    msg_number=376,\n    htype='series_end'\n)\n</code></pre> Source code in <code>dranspose/data/stream1.py</code> <pre><code>class Stream1End(Stream1):\n    \"\"\"\n    Example:\n        ``` py\n        Stream1End(\n            msg_number=376,\n            htype='series_end'\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    htype: Literal[\"series_end\"] = \"series_end\"\n</code></pre>"},{"location":"reference/protocols/STINS/#dranspose.data.stream1.Stream1Start","title":"<code>Stream1Start</code>","text":"<p>               Bases: <code>Stream1</code></p> Example <pre><code>Stream1Start(\n    msg_number=374,\n    htype='header',\n    filename='/data/visitors/....test.h5'\n)\n</code></pre> Source code in <code>dranspose/data/stream1.py</code> <pre><code>class Stream1Start(Stream1):\n    \"\"\"\n    Example:\n        ``` py\n        Stream1Start(\n            msg_number=374,\n            htype='header',\n            filename='/data/visitors/....test.h5'\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    htype: Literal[\"header\"] = \"header\"\n    filename: str\n</code></pre>"},{"location":"reference/protocols/albaem/","title":"Albaem","text":""},{"location":"reference/protocols/albaem/#dranspose.data.albaem.AlbaemPacket","title":"<code>AlbaemPacket = TypeAdapter(AlbaemStart | AlbaemData | AlbaemEnd)</code>  <code>module-attribute</code>","text":"<p>Union type for Albaem packets</p>"},{"location":"reference/protocols/albaem/#dranspose.data.albaem.AlbaemData","title":"<code>AlbaemData</code>","text":"<p>               Bases: <code>AlbaemBase</code></p> <p>While the original stream sends 3 separate zmq frames (no multipart), this returns a single packet.</p> Example <pre><code>AlbaemImage(\n    message_id=2,\n    version=1,\n    message_type='data',\n    frame_number=0,\n    timestamp=7.72645192,\n    acquisition_timestamp=1704807770443944912,\n    channel1=-2.8302592615927417e-11,\n    channel2=-6.091210149949596e-11,\n    channel3=2.5349278603830644e-10,\n    channel4=4.80528800718246e-10\n)\n</code></pre> Source code in <code>dranspose/data/albaem.py</code> <pre><code>class AlbaemData(AlbaemBase):\n    \"\"\"\n    While the original stream sends 3 separate zmq frames (no multipart), this returns a single packet.\n\n    Example:\n        ``` py\n        AlbaemImage(\n            message_id=2,\n            version=1,\n            message_type='data',\n            frame_number=0,\n            timestamp=7.72645192,\n            acquisition_timestamp=1704807770443944912,\n            channel1=-2.8302592615927417e-11,\n            channel2=-6.091210149949596e-11,\n            channel3=2.5349278603830644e-10,\n            channel4=4.80528800718246e-10\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    message_type: Literal[\"data\"]\n    frame_number: int\n    timestamp: float\n    acquisition_timestamp: int\n</code></pre>"},{"location":"reference/protocols/albaem/#dranspose.data.albaem.AlbaemEnd","title":"<code>AlbaemEnd</code>","text":"<p>               Bases: <code>AlbaemBase</code></p> Example <pre><code>AlbaemEnd(\n    message_id=6,\n    version=1,\n    message_type='series-end',\n    detector_specific={'read_overflow': False, 'memory_overflow': False})\n</code></pre> Source code in <code>dranspose/data/albaem.py</code> <pre><code>class AlbaemEnd(AlbaemBase):\n    \"\"\"\n    Example:\n        ``` py\n        AlbaemEnd(\n            message_id=6,\n            version=1,\n            message_type='series-end',\n            detector_specific={'read_overflow': False, 'memory_overflow': False})\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    message_type: Literal[\"series-end\"]\n</code></pre>"},{"location":"reference/protocols/albaem/#dranspose.data.albaem.AlbaemStart","title":"<code>AlbaemStart</code>","text":"<p>               Bases: <code>AlbaemBase</code></p> Example <pre><code>AlbaemStart(\n    message_id=1,\n    version=1,\n    message_type='series-start'\n)\n</code></pre> Source code in <code>dranspose/data/albaem.py</code> <pre><code>class AlbaemStart(AlbaemBase):\n    \"\"\"\n    Example:\n        ``` py\n        AlbaemStart(\n            message_id=1,\n            version=1,\n            message_type='series-start'\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    message_type: Literal[\"series-start\"]\n</code></pre>"},{"location":"reference/protocols/contrast/","title":"Contrast","text":""},{"location":"reference/protocols/contrast/#dranspose.data.contrast.ContrastPacket","title":"<code>ContrastPacket = TypeAdapter(ContrastStarted | ContrastRunning | ContrastFinished | ContrastHeartbeat)</code>  <code>module-attribute</code>","text":"<p>A union type for contrast packets</p>"},{"location":"reference/protocols/contrast/#dranspose.data.contrast.ContrastFinished","title":"<code>ContrastFinished</code>","text":"<p>               Bases: <code>ContrastBase</code></p> Example <pre><code>ContrastFinished(\n    status='finished',\n    path='/data/.../diff_1130_stream_test/raw/dummy',\n    scannr=2,\n    description='mesh sx -2 2 3 sy -2 2 4 0.1',\n    snapshot={'attenuator1_x': 0.048,\n              'attenuator2_x': 0.066,\n              'vfm_yaw': 0.15148492851039919,\n              'xrf_x': 94.99875}\n)\n</code></pre> Source code in <code>dranspose/data/contrast.py</code> <pre><code>class ContrastFinished(ContrastBase):\n    \"\"\"\n    Example:\n        ```python\n        ContrastFinished(\n            status='finished',\n            path='/data/.../diff_1130_stream_test/raw/dummy',\n            scannr=2,\n            description='mesh sx -2 2 3 sy -2 2 4 0.1',\n            snapshot={'attenuator1_x': 0.048,\n                      'attenuator2_x': 0.066,\n                      'vfm_yaw': 0.15148492851039919,\n                      'xrf_x': 94.99875}\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    status: Literal[\"finished\"] = \"finished\"\n    path: str\n    scannr: int\n    description: str\n</code></pre>"},{"location":"reference/protocols/contrast/#dranspose.data.contrast.ContrastHeartbeat","title":"<code>ContrastHeartbeat</code>","text":"<p>               Bases: <code>ContrastBase</code></p> <p>Heartbeat message</p> Source code in <code>dranspose/data/contrast.py</code> <pre><code>class ContrastHeartbeat(ContrastBase):\n    \"\"\"\n    Heartbeat message\n    \"\"\"\n\n    status: Literal[\"heartbeat\"]\n</code></pre>"},{"location":"reference/protocols/contrast/#dranspose.data.contrast.ContrastRunning","title":"<code>ContrastRunning</code>","text":"<p>               Bases: <code>ContrastBase</code></p> Example <pre><code>ContrastRunning(\n    status='running',\n    dt=2.410903215408325,\n    sx=-2.000431059888797,\n    sy=-2.0011940002441406,\n    pseudo={\n        'x': array([-2.00405186]),\n        'y': array([-2.00290304]),\n        'z': array([0.00029938]),\n        'analog_x': array([-1.99962707]),\n        'analog_y': array([-1.99349905]),\n        'analog_z': array([-0.00306218])\n    },\n    panda0={\n        'COUNTER1.OUT_Value': array([0.]),\n        'COUNTER2.OUT_Value': array([0.]),\n        'COUNTER3.OUT_Value': array([0.]),\n        'FMC_IN.VAL6_Mean': array([0.04644599]),\n        'FMC_IN.VAL7_Mean': array([-0.02943451]),\n        'FMC_IN.VAL8_Mean': array([0.01255371])\n    },\n    xspress3={\n        'type': 'Link',\n        'filename': '/data/.../diff_1130_stream_test/raw/dummy/scan_000002_xspress3.hdf5',\n        'path': '/entry/instrument/xspress3/',\n        'universal': True\n    }\n)\n</code></pre> Source code in <code>dranspose/data/contrast.py</code> <pre><code>class ContrastRunning(ContrastBase):\n    \"\"\"\n    Example:\n        ``` py\n        ContrastRunning(\n            status='running',\n            dt=2.410903215408325,\n            sx=-2.000431059888797,\n            sy=-2.0011940002441406,\n            pseudo={\n                'x': array([-2.00405186]),\n                'y': array([-2.00290304]),\n                'z': array([0.00029938]),\n                'analog_x': array([-1.99962707]),\n                'analog_y': array([-1.99349905]),\n                'analog_z': array([-0.00306218])\n            },\n            panda0={\n                'COUNTER1.OUT_Value': array([0.]),\n                'COUNTER2.OUT_Value': array([0.]),\n                'COUNTER3.OUT_Value': array([0.]),\n                'FMC_IN.VAL6_Mean': array([0.04644599]),\n                'FMC_IN.VAL7_Mean': array([-0.02943451]),\n                'FMC_IN.VAL8_Mean': array([0.01255371])\n            },\n            xspress3={\n                'type': 'Link',\n                'filename': '/data/.../diff_1130_stream_test/raw/dummy/scan_000002_xspress3.hdf5',\n                'path': '/entry/instrument/xspress3/',\n                'universal': True\n            }\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    status: Literal[\"running\"] = \"running\"\n    dt: float\n</code></pre>"},{"location":"reference/protocols/contrast/#dranspose.data.contrast.ContrastStarted","title":"<code>ContrastStarted</code>","text":"<p>               Bases: <code>ContrastBase</code></p> Example <pre><code>ContrastStarted(\n    status='started',\n    path='/data/.../diff_1130_stream_test/raw/dummy',\n    scannr=2,\n    description='mesh sx -2 2 3 sy -2 2 4 0.1',\n    snapshot={'attenuator1_x': 0.048,\n              'attenuator2_x': 0.067,\n              'attenuator3_x': 0.536,\n              'vfm_yaw': 0.15148492851039919,\n              'xrf_x': 94.99875}\n)\n</code></pre> Source code in <code>dranspose/data/contrast.py</code> <pre><code>class ContrastStarted(ContrastBase):\n    \"\"\"\n    Example:\n        ``` py\n        ContrastStarted(\n            status='started',\n            path='/data/.../diff_1130_stream_test/raw/dummy',\n            scannr=2,\n            description='mesh sx -2 2 3 sy -2 2 4 0.1',\n            snapshot={'attenuator1_x': 0.048,\n                      'attenuator2_x': 0.067,\n                      'attenuator3_x': 0.536,\n                      'vfm_yaw': 0.15148492851039919,\n                      'xrf_x': 94.99875}\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    status: Literal[\"started\"] = \"started\"\n    path: str\n    scannr: int\n    description: str\n</code></pre>"},{"location":"reference/protocols/eiger_legacy/","title":"Eiger legacy","text":""},{"location":"reference/protocols/eiger_legacy/#dranspose.data.eiger_legacy.EigerLegacyPacket","title":"<code>EigerLegacyPacket = TypeAdapter(EigerLegacyHeader | EigerLegacyImage | EigerLegacyEnd)</code>  <code>module-attribute</code>","text":"<p>A union type for Eiger Legacy packets</p>"},{"location":"reference/protocols/eiger_legacy/#dranspose.data.eiger_legacy.EigerLegacyEnd","title":"<code>EigerLegacyEnd</code>","text":"<p>               Bases: <code>EigerLegacy</code></p> Example <pre><code>EigerLegacyEnd(\n    htype='dseries_end-1.0'\n)\n</code></pre> Source code in <code>dranspose/data/eiger_legacy.py</code> <pre><code>class EigerLegacyEnd(EigerLegacy):\n    \"\"\"\n    Example:\n        ``` py\n        EigerLegacyEnd(\n            htype='dseries_end-1.0'\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    htype: Literal[\"dseries_end-1.0\"]\n</code></pre>"},{"location":"reference/protocols/eiger_legacy/#dranspose.data.eiger_legacy.EigerLegacyHeader","title":"<code>EigerLegacyHeader</code>","text":"<p>               Bases: <code>EigerLegacy</code></p> Example <pre><code>EigerLegacyHeader(\n    htype='dheader-1.0'\n    header_detail='all'\n    series=6\n    info={'auto_summation': True,\n          'beam_center_x': 0.0,\n          'beam_center_y': 0.0,\n          'bit_depth_image': 32,\n          'bit_depth_readout': 16,\n          'chi_increment': 0.0,\n          'chi_start': 0.0,\n          'compression': 'bslz4',\n          'count_time': 0.0099999,\n          'countrate_correction_applied': True,\n          'countrate_correction_count_cutoff': 83270,\n          'data_collection_date': '2024-03-12T15:29:58.142+01:00',\n          'description': 'Dectris EIGER2 CdTe 9M',\n          'detector_distance': 0.0,\n          'detector_number': 'E-18-0000',\n          'detector_readout_time': 1e-07,\n          'detector_translation': [0.0, 0.0, 0.0],\n          'eiger_fw_version': 'release-2022.1.1',\n          'element': '',\n          'flatfield_correction_applied': True,\n          'frame_count_time': 0.00499996,\n          'frame_period': 0.00499996,\n          'frame_time': 0.01,\n          'kappa_increment': 0.0,\n          'kappa_start': 0.0,\n          'nimages': 3,\n          'ntrigger': 1,\n          'number_of_excluded_pixels': 683998,\n          'omega_increment': 0.0,\n          'omega_start': 0.0,\n          'phi_increment': 0.0,\n          'phi_start': 0.0,\n          'photon_energy': 8041.0,\n          'pixel_mask_applied': True,\n          'roi_mode': '',\n          'sensor_material': 'CdTe',\n          'sensor_thickness': 0.00075,\n          'software_version': '1.8.0',\n          'threshold_energy': 4020.5,\n          'trigger_mode': 'ints',\n          'two_theta_increment': 0.0,\n          'two_theta_start': 0.0,\n          'virtual_pixel_correction_applied': True,\n          'wavelength': 1.5419002416764116,\n          'x_pixel_size': 7.5e-05,\n          'x_pixels_in_detector': 3108,\n          'y_pixel_size': 7.5e-05,\n          'y_pixels_in_detector': 3262}\n    appendix={'collect_dict': {\n                'col_id': 128579,\n                'process_dir': '/data/.../process',\n                'target_beam_size_factor': 0,\n                'ssx_mode': 'test',\n                'exp_type': 'test',\n                'shape_id': '2DP1',\n                'col': 0,\n                'row': 0},\n              'dozor_dict': {\n                'x_pixels_in_detector': 3108,\n                'omega_increment': None,\n                'count_time': 0.0099999,\n                'detector_distance': 0.0,\n                'beam_center_y': 0.0,\n                'beam_center_x': 0.0,\n                'y_pixels_in_detector': 3262,\n                'wavelength': 1.541900241676412,\n                'countrate_correction_count_cutoff': 83270,\n                'x_pixel_size': 7.5e-05}\n              }\n)\n</code></pre> Source code in <code>dranspose/data/eiger_legacy.py</code> <pre><code>class EigerLegacyHeader(EigerLegacy):\n    \"\"\"\n    Example:\n        ``` py\n        EigerLegacyHeader(\n            htype='dheader-1.0'\n            header_detail='all'\n            series=6\n            info={'auto_summation': True,\n                  'beam_center_x': 0.0,\n                  'beam_center_y': 0.0,\n                  'bit_depth_image': 32,\n                  'bit_depth_readout': 16,\n                  'chi_increment': 0.0,\n                  'chi_start': 0.0,\n                  'compression': 'bslz4',\n                  'count_time': 0.0099999,\n                  'countrate_correction_applied': True,\n                  'countrate_correction_count_cutoff': 83270,\n                  'data_collection_date': '2024-03-12T15:29:58.142+01:00',\n                  'description': 'Dectris EIGER2 CdTe 9M',\n                  'detector_distance': 0.0,\n                  'detector_number': 'E-18-0000',\n                  'detector_readout_time': 1e-07,\n                  'detector_translation': [0.0, 0.0, 0.0],\n                  'eiger_fw_version': 'release-2022.1.1',\n                  'element': '',\n                  'flatfield_correction_applied': True,\n                  'frame_count_time': 0.00499996,\n                  'frame_period': 0.00499996,\n                  'frame_time': 0.01,\n                  'kappa_increment': 0.0,\n                  'kappa_start': 0.0,\n                  'nimages': 3,\n                  'ntrigger': 1,\n                  'number_of_excluded_pixels': 683998,\n                  'omega_increment': 0.0,\n                  'omega_start': 0.0,\n                  'phi_increment': 0.0,\n                  'phi_start': 0.0,\n                  'photon_energy': 8041.0,\n                  'pixel_mask_applied': True,\n                  'roi_mode': '',\n                  'sensor_material': 'CdTe',\n                  'sensor_thickness': 0.00075,\n                  'software_version': '1.8.0',\n                  'threshold_energy': 4020.5,\n                  'trigger_mode': 'ints',\n                  'two_theta_increment': 0.0,\n                  'two_theta_start': 0.0,\n                  'virtual_pixel_correction_applied': True,\n                  'wavelength': 1.5419002416764116,\n                  'x_pixel_size': 7.5e-05,\n                  'x_pixels_in_detector': 3108,\n                  'y_pixel_size': 7.5e-05,\n                  'y_pixels_in_detector': 3262}\n            appendix={'collect_dict': {\n                        'col_id': 128579,\n                        'process_dir': '/data/.../process',\n                        'target_beam_size_factor': 0,\n                        'ssx_mode': 'test',\n                        'exp_type': 'test',\n                        'shape_id': '2DP1',\n                        'col': 0,\n                        'row': 0},\n                      'dozor_dict': {\n                        'x_pixels_in_detector': 3108,\n                        'omega_increment': None,\n                        'count_time': 0.0099999,\n                        'detector_distance': 0.0,\n                        'beam_center_y': 0.0,\n                        'beam_center_x': 0.0,\n                        'y_pixels_in_detector': 3262,\n                        'wavelength': 1.541900241676412,\n                        'countrate_correction_count_cutoff': 83270,\n                        'x_pixel_size': 7.5e-05}\n                      }\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    htype: Literal[\"dheader-1.0\"]\n</code></pre>"},{"location":"reference/protocols/eiger_legacy/#dranspose.data.eiger_legacy.EigerLegacyImage","title":"<code>EigerLegacyImage</code>","text":"<p>               Bases: <code>EigerLegacy</code></p> Example <pre><code>EigerLegacyImage(\n    htype='dimage-1.0',\n    frame=0\n    hash='815e4907ce3482ec3cc4d33a1145cd44'\n    series=6\n    data={'encoding': 'bs32-lz4&lt;',\n          'htype': 'dimage_d-1.0',\n          'shape': [3108, 3262],\n          'size': 754672,\n          'type': 'uint32',\n          'buffer': b'\u0000\u0000\u0000\u0000j\u00ca\u00e0...'\n    config={'htype': 'dconfig-1.0',\n            'real_time': 9999900,\n            'start_time': 103597359252740,\n            'stop_time': 103597369252640}\n)\n</code></pre> Source code in <code>dranspose/data/eiger_legacy.py</code> <pre><code>class EigerLegacyImage(EigerLegacy):\n    \"\"\"\n    Example:\n        ``` py\n        EigerLegacyImage(\n            htype='dimage-1.0',\n            frame=0\n            hash='815e4907ce3482ec3cc4d33a1145cd44'\n            series=6\n            data={'encoding': 'bs32-lz4&lt;',\n                  'htype': 'dimage_d-1.0',\n                  'shape': [3108, 3262],\n                  'size': 754672,\n                  'type': 'uint32',\n                  'buffer': b'\\x00\\x00\\x00\\x00\\x02j\\xca\\xe0...'\n            config={'htype': 'dconfig-1.0',\n                    'real_time': 9999900,\n                    'start_time': 103597359252740,\n                    'stop_time': 103597369252640}\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    htype: Literal[\"dimage-1.0\"]\n    frame: int\n</code></pre>"},{"location":"reference/protocols/events/","title":"Events","text":""},{"location":"reference/protocols/events/#dranspose.event.EventData","title":"<code>EventData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Main container for an event provided to the worker function</p> <p>Attributes:</p> Name Type Description <code>event_number</code> <code>EventNumber</code> <p>Current event number relative to the trigger map provided</p> <code>streams</code> <code>dict[StreamName, StreamData]</code> <p>Data for each stream present in the event</p> Source code in <code>dranspose/event.py</code> <pre><code>class EventData(BaseModel):\n    \"\"\"\n    Main container for an event provided to the worker function\n\n    Attributes:\n        event_number:    Current event number relative to the trigger map provided\n        streams:         Data for each stream present in the event\n    \"\"\"\n\n    event_number: EventNumber\n    streams: dict[StreamName, StreamData]\n\n    @classmethod\n    def from_internals(cls, msgs: list[InternalWorkerMessage]) -&gt; \"EventData\":\n        \"\"\"\n        Helper function to assemble an event from the internal messages received from the ingesters.\n        This is a factory method\n\n        Args:\n             msgs: Internal messages each containing a subset of the streams for the event\n\n        Returns:\n            A new object with all data combined.\n        \"\"\"\n        assert len(msgs) &gt; 0, \"merge at least one message\"\n        assert (\n            len(set([m.event_number for m in msgs])) == 1\n        ), f\"Cannot merge data from events {[m.event_number for m in msgs]}\"\n        all_stream_names = [stream for m in msgs for stream in m.streams.keys()]\n        assert len(all_stream_names) == len(\n            set(all_stream_names)\n        ), \"Cannot merge data with duplicate streams\"\n\n        ret = EventData(event_number=msgs[0].event_number, streams={})\n        for msg in msgs:\n            ret.streams.update(msg.streams)\n        return ret\n</code></pre>"},{"location":"reference/protocols/events/#dranspose.event.EventData.from_internals","title":"<code>from_internals(msgs)</code>  <code>classmethod</code>","text":"<p>Helper function to assemble an event from the internal messages received from the ingesters. This is a factory method</p> <p>Parameters:</p> Name Type Description Default <code>msgs</code> <code>list[InternalWorkerMessage]</code> <p>Internal messages each containing a subset of the streams for the event</p> required <p>Returns:</p> Type Description <code>EventData</code> <p>A new object with all data combined.</p> Source code in <code>dranspose/event.py</code> <pre><code>@classmethod\ndef from_internals(cls, msgs: list[InternalWorkerMessage]) -&gt; \"EventData\":\n    \"\"\"\n    Helper function to assemble an event from the internal messages received from the ingesters.\n    This is a factory method\n\n    Args:\n         msgs: Internal messages each containing a subset of the streams for the event\n\n    Returns:\n        A new object with all data combined.\n    \"\"\"\n    assert len(msgs) &gt; 0, \"merge at least one message\"\n    assert (\n        len(set([m.event_number for m in msgs])) == 1\n    ), f\"Cannot merge data from events {[m.event_number for m in msgs]}\"\n    all_stream_names = [stream for m in msgs for stream in m.streams.keys()]\n    assert len(all_stream_names) == len(\n        set(all_stream_names)\n    ), \"Cannot merge data with duplicate streams\"\n\n    ret = EventData(event_number=msgs[0].event_number, streams={})\n    for msg in msgs:\n        ret.streams.update(msg.streams)\n    return ret\n</code></pre>"},{"location":"reference/protocols/events/#dranspose.event.InternalWorkerMessage","title":"<code>InternalWorkerMessage</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A container for partial events which carries one or more streams. This is the message between ingesters and workers.</p> <p>Attributes:</p> Name Type Description <code>event_number</code> <code>EventNumber</code> <p>event number</p> <code>streams</code> <code>dict[StreamName, StreamData]</code> <p>one or more streams from an ingester</p> Source code in <code>dranspose/event.py</code> <pre><code>class InternalWorkerMessage(BaseModel):\n    \"\"\"\n    A container for partial events which carries one or more streams. This is the message between ingesters and workers.\n\n    Attributes:\n        event_number: event number\n        streams: one or more streams from an ingester\n    \"\"\"\n\n    event_number: EventNumber\n    streams: dict[StreamName, StreamData] = {}\n    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n\n    def get_all_frames(self) -&gt; list[zmq.Frame | bytes]:\n        return [frame for stream in self.streams.values() for frame in stream.frames]\n</code></pre>"},{"location":"reference/protocols/events/#dranspose.event.ResultData","title":"<code>ResultData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Container for transferring results from the worker to the reducer. In enhances the pure payload with useful meta data</p> <p>Attributes:</p> Name Type Description <code>event_number</code> <code>EventNumber</code> <p>which event the result belongs to. NB: results may arrive out of order</p> <code>worker</code> <code>WorkerName</code> <p>which worker processed it.</p> <code>parameters_hash</code> <code>Optional[HashDigest]</code> <p>which version of parameters was used to process the event</p> <code>payload</code> <code>Any</code> <p>the data return from the custom worker function: process_event</p> Source code in <code>dranspose/event.py</code> <pre><code>class ResultData(BaseModel):\n    \"\"\"\n    Container for transferring results from the worker to the reducer. In enhances the pure payload with useful meta data\n\n    Attributes:\n        event_number: which event the result belongs to. NB: results may arrive out of order\n        worker: which worker processed it.\n        parameters_hash: which version of parameters was used to process the event\n        payload: the data return from the custom worker function: process_event\n    \"\"\"\n\n    event_number: EventNumber\n    worker: WorkerName\n    parameters_hash: Optional[HashDigest]\n    payload: Any\n</code></pre>"},{"location":"reference/protocols/events/#dranspose.event.StreamData","title":"<code>StreamData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Data container for a single stream with all zmq frames belonging to it</p> <p>Attributes:</p> Name Type Description <code>typ</code> <code>str</code> <p>arbitrary typ set by the ingester to common parsing</p> <code>frames</code> <code>list[Frame] | list[bytes]</code> <p>all frames received for this event for the stream</p> Source code in <code>dranspose/event.py</code> <pre><code>class StreamData(BaseModel):\n    \"\"\"\n    Data container for a single stream with all zmq frames belonging to it\n\n    Attributes:\n         typ: arbitrary typ set by the ingester to common parsing\n         frames: all frames received for this event for the stream\n    \"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    typ: str\n    frames: list[zmq.Frame] | list[bytes]\n\n    @computed_field  # type: ignore[prop-decorator]\n    @property\n    def length(self) -&gt; int:\n        \"\"\"\n        Calculates the length of frames.\n\n        Returns:\n             length of frames\n        \"\"\"\n        return len(self.frames)\n\n    def get_bytes(self) -&gt; \"StreamData\":\n        \"\"\"\n        Copies the data from the zmq buffer\n\n        Returns:\n             An object with a list of bytes.\n        \"\"\"\n        return StreamData(\n            typ=self.typ,\n            frames=[\n                frame.bytes if isinstance(frame, zmq.Frame) else frame\n                for frame in self.frames\n            ],\n        )\n</code></pre>"},{"location":"reference/protocols/events/#dranspose.event.StreamData.length","title":"<code>length</code>  <code>property</code>","text":"<p>Calculates the length of frames.</p> <p>Returns:</p> Type Description <code>int</code> <p>length of frames</p>"},{"location":"reference/protocols/events/#dranspose.event.StreamData.get_bytes","title":"<code>get_bytes()</code>","text":"<p>Copies the data from the zmq buffer</p> <p>Returns:</p> Type Description <code>StreamData</code> <p>An object with a list of bytes.</p> Source code in <code>dranspose/event.py</code> <pre><code>def get_bytes(self) -&gt; \"StreamData\":\n    \"\"\"\n    Copies the data from the zmq buffer\n\n    Returns:\n         An object with a list of bytes.\n    \"\"\"\n    return StreamData(\n        typ=self.typ,\n        frames=[\n            frame.bytes if isinstance(frame, zmq.Frame) else frame\n            for frame in self.frames\n        ],\n    )\n</code></pre>"},{"location":"reference/protocols/events/#dranspose.protocol.EventNumber","title":"<code>EventNumber = NewType('EventNumber', int)</code>  <code>module-attribute</code>","text":"<p>strongly typed event number (int)</p>"},{"location":"reference/protocols/events/#dranspose.protocol.StreamName","title":"<code>StreamName = NewType('StreamName', str)</code>  <code>module-attribute</code>","text":"<p>strongly typed stream name (str)</p>"},{"location":"reference/protocols/events/#dranspose.protocol.VirtualConstraint","title":"<code>VirtualConstraint = NewType('VirtualConstraint', int)</code>  <code>module-attribute</code>","text":"<p>Stronly typed constraint for workers (int)</p>"},{"location":"reference/protocols/events/#dranspose.protocol.WorkerTag","title":"<code>WorkerTag = NewType('WorkerTag', _WorkerTagT)</code>  <code>module-attribute</code>","text":"<p>Strongly typed worker tag (str)</p>"},{"location":"reference/protocols/events/#dranspose.protocol.VirtualWorker","title":"<code>VirtualWorker</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>virtual worker with a number and tags</p> <p>Attributes:</p> Name Type Description <code>tags</code> <code>set[WorkerTag]</code> <p>set of tags which a worker must have to get this event</p> <code>constraint</code> <code>Optional[VirtualConstraint]</code> <p>a VirtualConstraint to which worker this event should be delivered, if None, deliver to all workers with matching tags</p> Source code in <code>dranspose/protocol.py</code> <pre><code>class VirtualWorker(BaseModel):\n    \"\"\"\n    virtual worker with a number and tags\n\n    Attributes:\n        tags: set of tags which a worker must have to get this event\n        constraint: a VirtualConstraint to which worker this event should be delivered, if None, deliver to all workers with matching tags\n    \"\"\"\n\n    tags: set[WorkerTag] = {GENERIC_WORKER}\n    constraint: Optional[VirtualConstraint] = None\n</code></pre>"},{"location":"reference/protocols/lecroy/","title":"Lecroy","text":""},{"location":"reference/protocols/lecroy/#dranspose.data.lecroy.LecroyPacket","title":"<code>LecroyPacket = TypeAdapter(LecroyPrepare | LecroySeqStart | LecroyEnd | LecroySeqEnd | LecroyData | LecroyParsed)</code>  <code>module-attribute</code>","text":"<p>Union type for Lecroy packets</p>"},{"location":"reference/protocols/lecroy/#dranspose.data.lecroy.LecroyData","title":"<code>LecroyData</code>","text":"<p>               Bases: <code>LecroyBase</code></p> <p>Each \"traces\" message has 3 zmq parts: metadata (json), waveforms (np.array), timestamps (list)</p> Example <pre><code>LecroyData(\n    htype='traces',\n    ch: 2,\n    ts: 1740563614.969933,\n    frame: 0,\n    shape: [1, 8002],\n    horiz_offset: -1.0000505879544622e-07,\n    horiz_interval: 1.25000001668929e-11,\n    dtype: \"float64\"\n    )\n</code></pre> Source code in <code>dranspose/data/lecroy.py</code> <pre><code>class LecroyData(LecroyBase):\n    # len(parts) parts[0]\n    # 3 b'{\"htype\": \"traces\", \"ch\": 2, \"ts\": 1740563614.969933, \"frame\": 0, \"shape\": [1, 8002], \"horiz_offset\": -1.0000505879544622e-07, \"horiz_interval\": 1.25000001668929e-11, \"dtype\": \"float64\"}'\n    \"\"\"\n    Each \"traces\" message has 3 zmq parts:\n    metadata (json), waveforms (np.array), timestamps (list)\n\n    Example:\n        ``` py\n        LecroyData(\n            htype='traces',\n            ch: 2,\n            ts: 1740563614.969933,\n            frame: 0,\n            shape: [1, 8002],\n            horiz_offset: -1.0000505879544622e-07,\n            horiz_interval: 1.25000001668929e-11,\n            dtype: \"float64\"\n            )\n        ```\n    \"\"\"\n\n    htype: Literal[\"traces\"]\n    ch: int\n    ts: float\n    frame: int\n    shape: List[int]\n    dtype: str\n    horiz_offset: float\n    horiz_interval: float\n</code></pre>"},{"location":"reference/protocols/lecroy/#dranspose.data.lecroy.LecroyEnd","title":"<code>LecroyEnd</code>","text":"<p>               Bases: <code>LecroyBase</code></p> Example <pre><code>LecroyEnd(\n    htype='msg'\n    what=3,\n    frame=66,\n    frames=66,\n)\n</code></pre> Source code in <code>dranspose/data/lecroy.py</code> <pre><code>class LecroyEnd(LecroyBase):\n    # len(parts) parts[0]\n    \"\"\"\n    Example:\n        ``` py\n        LecroyEnd(\n            htype='msg'\n            what=3,\n            frame=66,\n            frames=66,\n        )\n        ```\n    \"\"\"\n\n    frames: int\n    what: Literal[WhatEnum.STOP]  # STOP = 3\n</code></pre>"},{"location":"reference/protocols/lecroy/#dranspose.data.lecroy.LecroyPrepare","title":"<code>LecroyPrepare</code>","text":"<p>               Bases: <code>LecroyBase</code></p> Example <pre><code>LecroyStart(\n    htype='msg'\n    what=0,\n    frame=0,\n)\n</code></pre> Source code in <code>dranspose/data/lecroy.py</code> <pre><code>class LecroyPrepare(LecroyBase):\n    # len(parts) parts[0]\n    # 1 b'{\"htype\": \"msg\", \"what\": 0, \"frame\": 0}'\n    \"\"\"\n    Example:\n        ``` py\n        LecroyStart(\n            htype='msg'\n            what=0,\n            frame=0,\n        )\n        ```\n    \"\"\"\n\n    htype: Literal[\"msg\"]\n    what: Literal[WhatEnum.PREPARE]  # PREPARE = 0\n</code></pre>"},{"location":"reference/protocols/lecroy/#dranspose.data.lecroy.LecroySeqEnd","title":"<code>LecroySeqEnd</code>","text":"<p>               Bases: <code>LecroyBase</code></p> Example <pre><code>LecroySeqEnd(\n    htype='msg'\n    what=2,\n    frame=2,\n)\n</code></pre> Source code in <code>dranspose/data/lecroy.py</code> <pre><code>class LecroySeqEnd(LecroyBase):\n    # len(parts) parts[0]\n    # 1 b'{\"htype\": \"msg\", \"what\": 2, \"frame\": 2}'\n    \"\"\"\n    Example:\n        ``` py\n        LecroySeqEnd(\n            htype='msg'\n            what=2,\n            frame=2,\n        )\n        ```\n    \"\"\"\n\n    htype: Literal[\"msg\"]\n    what: Literal[WhatEnum.SEQEND]  # SEQEND = 2\n</code></pre>"},{"location":"reference/protocols/lecroy/#dranspose.data.lecroy.LecroySeqStart","title":"<code>LecroySeqStart</code>","text":"<p>               Bases: <code>LecroyBase</code></p> Example <pre><code>LecroyStart(\n    htype='msg'\n    what=1,\n    frame=0,\n    ntriggers=-1\n    seqno=0\n    channels=[2, 4]\n)\n</code></pre> Source code in <code>dranspose/data/lecroy.py</code> <pre><code>class LecroySeqStart(LecroyBase):\n    # len(parts) parts[0]\n    # 1 b'{\"htype\": \"msg\", \"what\": 1, \"frame\": 0, \"ntriggers\": -1, \"seqno\": 0, \"channels\": [2, 4]}'\n    \"\"\"\n    Example:\n        ``` py\n        LecroyStart(\n            htype='msg'\n            what=1,\n            frame=0,\n            ntriggers=-1\n            seqno=0\n            channels=[2, 4]\n        )\n        ```\n    \"\"\"\n\n    htype: Literal[\"msg\"]\n    what: Literal[WhatEnum.START]  # START = 1\n    ntriggers: int\n    seqno: int\n    channels: List[int]\n</code></pre>"},{"location":"reference/protocols/pcap/","title":"Pcap","text":""},{"location":"reference/protocols/pcap/#dranspose.data.pcap.PCAPPacket","title":"<code>PCAPPacket = TypeAdapter(PCAPStart | PCAPData | PCAPEnd)</code>  <code>module-attribute</code>","text":"<p>Union type for PCAP packets</p>"},{"location":"reference/protocols/pcap/#dranspose.data.pcap.PCAPData","title":"<code>PCAPData</code>","text":"<p>               Bases: <code>PCAPBase</code></p> <p>While the original stream sends 3 separate zmq frames (no multipart), this returns a single packet.</p> Example <pre><code>PCAPImage(\n    message_id=2,\n    version=1,\n    message_type=\"data\",\n    frame_number=0,\n    inttime=[7.1160000000000005, 7.315, 7.093800000000001, 7.1584, 7.1322, 7.1062, 7.0206, 6.9082, 7.0164, 6.912, 6.966, 6.885000000000001, 6.7946, 6.731800000000001, 6.9636000000000005],\n    triggernumber=[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0],\n    repeatindex=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n    energy=[8879.101048716273, 8879.299376689953, 8879.5003861779, 8879.699330779304, 8879.8999612314, 8880.099636263549, 8880.300291637586, 8880.499422033765, 8880.700264322526, 8880.900116547104, 8881.099615570443, 8881.29966467182, 8881.499998985424, 8881.700179495409, 8881.900461311128],\n    INENC3.VAL.Mean=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n</code></pre> Source code in <code>dranspose/data/pcap.py</code> <pre><code>class PCAPData(PCAPBase):\n    \"\"\"\n    While the original stream sends 3 separate zmq frames (no multipart), this returns a single packet.\n\n    Example:\n        ``` py\n        PCAPImage(\n            message_id=2,\n            version=1,\n            message_type=\"data\",\n            frame_number=0,\n            inttime=[7.1160000000000005, 7.315, 7.093800000000001, 7.1584, 7.1322, 7.1062, 7.0206, 6.9082, 7.0164, 6.912, 6.966, 6.885000000000001, 6.7946, 6.731800000000001, 6.9636000000000005],\n            triggernumber=[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0],\n            repeatindex=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n            energy=[8879.101048716273, 8879.299376689953, 8879.5003861779, 8879.699330779304, 8879.8999612314, 8880.099636263549, 8880.300291637586, 8880.499422033765, 8880.700264322526, 8880.900116547104, 8881.099615570443, 8881.29966467182, 8881.499998985424, 8881.700179495409, 8881.900461311128],\n            INENC3.VAL.Mean=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    message_type: Literal[\"data\"]\n    frame_number: int\n</code></pre>"},{"location":"reference/protocols/pcap/#dranspose.data.pcap.PCAPEnd","title":"<code>PCAPEnd</code>","text":"<p>               Bases: <code>PCAPBase</code></p> Example <pre><code>PCAPEnd(\n    message_id=6,\n    version=1,\n    message_type='series-end')\n</code></pre> Source code in <code>dranspose/data/pcap.py</code> <pre><code>class PCAPEnd(PCAPBase):\n    \"\"\"\n    Example:\n        ``` py\n        PCAPEnd(\n            message_id=6,\n            version=1,\n            message_type='series-end')\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    message_type: Literal[\"series-end\"]\n</code></pre>"},{"location":"reference/protocols/pcap/#dranspose.data.pcap.PCAPStart","title":"<code>PCAPStart</code>","text":"<p>               Bases: <code>PCAPBase</code></p> Example <pre><code>PCAPStart(\n    message_id=1,\n    version=1,\n    message_type='series-start'\n    arm_time=\"2024-10-07T08:49:10.627Z\"\n)\n</code></pre> Source code in <code>dranspose/data/pcap.py</code> <pre><code>class PCAPStart(PCAPBase):\n    \"\"\"\n    Example:\n        ``` py\n        PCAPStart(\n            message_id=1,\n            version=1,\n            message_type='series-start'\n            arm_time=\"2024-10-07T08:49:10.627Z\"\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    message_type: Literal[\"series-start\"]\n    arm_time: datetime\n</code></pre>"},{"location":"reference/protocols/positioncap/","title":"Positioncap","text":"<p>This is a raw connection to the PandAbox capture port. If possible avoid using this directly as it may lead to hanging scans if the data is not consumed. </p>"},{"location":"reference/protocols/positioncap/#dranspose.data.positioncap.PositionCapPacket","title":"<code>PositionCapPacket = TypeAdapter(PositionCapStart | PositionCapValues | PositionCapEnd)</code>  <code>module-attribute</code>","text":"<p>A union type for PCAP_RAW packets</p>"},{"location":"reference/protocols/sardana/","title":"Sardana","text":""},{"location":"reference/protocols/sardana/#dranspose.data.sardana.SardanaPacket","title":"<code>SardanaPacket = TypeAdapter(SardanaDataDescription | SardanaRecordData | SardanaRecordEnd)</code>  <code>module-attribute</code>","text":"<p>Union type for Sardana packets</p>"},{"location":"reference/protocols/sardana/#dranspose.data.sardana.SardanaDataDescription","title":"<code>SardanaDataDescription</code>","text":"<p>               Bases: <code>BaseModel</code></p> Example <pre><code>SardanaDataDescription(\n    type='DataDescription',\n    serialno=20338,\n    scandir='/data/staff/femtomax/20230413',\n    title='burstscan dummy_mot_01 0.0 0.1 2 50',\n    column_desc=[{\n        'name': 'point_nb',\n        'label': '#Pt No',\n        'dtype':\n        'int64',\n        'shape': []\n        }, {\n        'min_value': 0,\n        'max_value': 0.1,\n        'instrument': '',\n        'name': 'dummy_mot_01',\n        'label': 'dummy_mot_01',\n        'dtype': 'float64',\n        'shape': [],\n        'is_reference': True\n        }, {\n        'name': 'timestamp',\n        'label': 'dt',\n        'dtype': 'float64',\n        'shape': []}\n    ],\n    ref_moveables=['dummy_mot_01'],\n    estimatedtime=-2.6585786096205566,\n    total_scan_intervals=2,\n    starttime='Mon Apr 17 14:19:35 2023',\n    counters=['tango://b-v-femtomax-csdb-0.maxiv.lu.se:10000/expchan/oscc_02_seq_ctrl/1',\n    'tango://b-v-femtomax-csdb-0.maxiv.lu.se:10000/expchan/panda_femtopcap_ctrl/4',\n    'tango://b-v-femtomax-csdb-0.maxiv.lu.se:10000/expchan/panda_femtopcap_ctrl/5'],\n    scanfile=['stream.daq', 'tests_03.h5']\n)\n</code></pre> Source code in <code>dranspose/data/sardana.py</code> <pre><code>class SardanaDataDescription(BaseModel):\n    \"\"\"\n    Example:\n        ```python\n        SardanaDataDescription(\n            type='DataDescription',\n            serialno=20338,\n            scandir='/data/staff/femtomax/20230413',\n            title='burstscan dummy_mot_01 0.0 0.1 2 50',\n            column_desc=[{\n                'name': 'point_nb',\n                'label': '#Pt No',\n                'dtype':\n                'int64',\n                'shape': []\n                }, {\n                'min_value': 0,\n                'max_value': 0.1,\n                'instrument': '',\n                'name': 'dummy_mot_01',\n                'label': 'dummy_mot_01',\n                'dtype': 'float64',\n                'shape': [],\n                'is_reference': True\n                }, {\n                'name': 'timestamp',\n                'label': 'dt',\n                'dtype': 'float64',\n                'shape': []}\n            ],\n            ref_moveables=['dummy_mot_01'],\n            estimatedtime=-2.6585786096205566,\n            total_scan_intervals=2,\n            starttime='Mon Apr 17 14:19:35 2023',\n            counters=['tango://b-v-femtomax-csdb-0.maxiv.lu.se:10000/expchan/oscc_02_seq_ctrl/1',\n            'tango://b-v-femtomax-csdb-0.maxiv.lu.se:10000/expchan/panda_femtopcap_ctrl/4',\n            'tango://b-v-femtomax-csdb-0.maxiv.lu.se:10000/expchan/panda_femtopcap_ctrl/5'],\n            scanfile=['stream.daq', 'tests_03.h5']\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n    type: Literal[\"DataDescription\"] = \"DataDescription\"\n    serialno: int\n    scandir: str\n    title: str\n</code></pre>"},{"location":"reference/protocols/sardana/#dranspose.data.sardana.SardanaRecordData","title":"<code>SardanaRecordData</code>","text":"<p>               Bases: <code>BaseModel</code></p> Example <pre><code>SardanaRecordData(\n    type='RecordData',\n    timestamp=0.6104741096496582,\n    point_nb=8,\n    dummy_mot_01=0\n)\n</code></pre> Source code in <code>dranspose/data/sardana.py</code> <pre><code>class SardanaRecordData(BaseModel):\n    \"\"\"\n    Example:\n        ```python\n        SardanaRecordData(\n            type='RecordData',\n            timestamp=0.6104741096496582,\n            point_nb=8,\n            dummy_mot_01=0\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n    type: Literal[\"RecordData\"] = \"RecordData\"\n    timestamp: float\n</code></pre>"},{"location":"reference/protocols/sardana/#dranspose.data.sardana.SardanaRecordEnd","title":"<code>SardanaRecordEnd</code>","text":"<p>               Bases: <code>BaseModel</code></p> Example <pre><code>SardanaRecordEnd(type='RecordEnd')\n</code></pre> Source code in <code>dranspose/data/sardana.py</code> <pre><code>class SardanaRecordEnd(BaseModel):\n    \"\"\"\n    Example:\n        ```python\n        SardanaRecordEnd(type='RecordEnd')\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n    type: Literal[\"RecordEnd\"] = \"RecordEnd\"\n</code></pre>"},{"location":"reference/protocols/xspress/","title":"Xspress","text":""},{"location":"reference/protocols/xspress/#dranspose.data.xspress3.XspressPacket","title":"<code>XspressPacket = TypeAdapter(XspressStart | XspressImage | XspressEnd)</code>  <code>module-attribute</code>","text":"<p>Union type for Xspress packets</p>"},{"location":"reference/protocols/xspress/#dranspose.data.xspress3.XspressEnd","title":"<code>XspressEnd</code>","text":"<p>               Bases: <code>XspressBase</code></p> Example <pre><code>XspressEnd(htype='series_end')\n</code></pre> Source code in <code>dranspose/data/xspress3.py</code> <pre><code>class XspressEnd(XspressBase):\n    \"\"\"\n    Example:\n        ``` py\n        XspressEnd(htype='series_end')\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    htype: Literal[\"series_end\"] = \"series_end\"\n</code></pre>"},{"location":"reference/protocols/xspress/#dranspose.data.xspress3.XspressImage","title":"<code>XspressImage</code>","text":"<p>               Bases: <code>XspressBase</code></p> <p>While the original stream sends 3 separate zmq frames (no multipart), this returns a single packet.</p> Example <pre><code>XspressImage(\n    htype='image',\n    frame=0,\n    shape=[4, 4096],\n    exptime=0.099999875,\n    type='uint32',\n    compression='none',\n    data=array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint32),\n    meta={\n        'ocr': array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.56250195e-15]),\n        'AllEvents': array([2, 0, 0, 3], dtype=uint32),\n        'AllGood': array([0, 0, 0, 1], dtype=uint32),\n        'ClockTicks': array([7999990, 7999990, 7999990, 7999990], dtype=uint32),\n        'TotalTicks': array([7999990, 7999990, 7999990, 7999990], dtype=uint32),\n        'ResetTicks': array([ 0,  0,  0, 91], dtype=uint32),\n        'event_widths': array([6, 6, 6, 6], dtype=int32),\n        'dtc': array([1.00000175, 1.        , 1.        , 1.000014  ])\n    }\n)\n</code></pre> Source code in <code>dranspose/data/xspress3.py</code> <pre><code>class XspressImage(XspressBase):\n    \"\"\"\n    While the original stream sends 3 separate zmq frames (no multipart), this returns a single packet.\n\n    Example:\n        ``` py\n        XspressImage(\n            htype='image',\n            frame=0,\n            shape=[4, 4096],\n            exptime=0.099999875,\n            type='uint32',\n            compression='none',\n            data=array([[0, 0, 0, ..., 0, 0, 0],\n               [0, 0, 0, ..., 0, 0, 0],\n               [0, 0, 0, ..., 0, 0, 0],\n               [0, 0, 0, ..., 0, 0, 0]], dtype=uint32),\n            meta={\n                'ocr': array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.56250195e-15]),\n                'AllEvents': array([2, 0, 0, 3], dtype=uint32),\n                'AllGood': array([0, 0, 0, 1], dtype=uint32),\n                'ClockTicks': array([7999990, 7999990, 7999990, 7999990], dtype=uint32),\n                'TotalTicks': array([7999990, 7999990, 7999990, 7999990], dtype=uint32),\n                'ResetTicks': array([ 0,  0,  0, 91], dtype=uint32),\n                'event_widths': array([6, 6, 6, 6], dtype=int32),\n                'dtc': array([1.00000175, 1.        , 1.        , 1.000014  ])\n            }\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    htype: Literal[\"image\"] = \"image\"\n    frame: int\n    shape: list[int]\n    exptime: Optional[float] = 1\n    type: str\n    compression: Optional[str] = \"none\"\n</code></pre>"},{"location":"reference/protocols/xspress/#dranspose.data.xspress3.XspressStart","title":"<code>XspressStart</code>","text":"<p>               Bases: <code>XspressBase</code></p> Example <pre><code>XspressStart(\n    htype='header',\n    filename='/data/.../diff_1130_stream_test/raw/dummy/scan_000002_xspress3.hdf5',\n    overwritable=False\n)\n</code></pre> Source code in <code>dranspose/data/xspress3.py</code> <pre><code>class XspressStart(XspressBase):\n    \"\"\"\n    Example:\n        ``` py\n        XspressStart(\n            htype='header',\n            filename='/data/.../diff_1130_stream_test/raw/dummy/scan_000002_xspress3.hdf5',\n            overwritable=False\n        )\n        ```\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    htype: Literal[\"header\"] = \"header\"\n    filename: str\n</code></pre>"},{"location":"tutorials/analysis/","title":"Getting Started - Analysis","text":"<p>This tutorial guides you to create a dranspose map-reduce analysis.</p>"},{"location":"tutorials/analysis/#preparations","title":"Preparations","text":"<p>First create a folder (e.g. <code>drp-example</code>) and a python virtual environment, e.g. with venv or conda.</p> <p>Install <code>dranspose</code> in it. Either use the release version or the main branch from maxiv internal or github. Run one of the following. <pre><code>pip install dranspose\npip install git+https://github.com/felix-engelmann/dranspose.git\npip install git+https://gitlab.maxiv.lu.se/scisw/daq-modules/dranspose.git\n</code></pre></p> <p>Info</p> <p>The maxiv git is the most up to date, the public github follows tightly. The official releases on pypi are only for bigger breaking changes.</p> <p>To keep track of your changes, make the new folder a git repository with  <pre><code>git init .\n</code></pre></p>"},{"location":"tutorials/analysis/#worker-and-reducer","title":"Worker and Reducer","text":"<p>For a base analysis we need a worker function and a reducer function. Initially they are both empty skeletons.</p> <p>It makes sense to separate the two required classes into separate files. The Worker class may be in <code>src/worker.py</code> and requires a <code>process_event</code> function as well as absorb optional arguments to <code>__init__</code>: <pre><code># src/worker.py\nclass TestWorker:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    def process_event(self, event, parameters=None):\n        pass\n</code></pre></p> <p>The reducer is similar and only requires a <code>process_result</code> function. e.g. in <code>src/reducer.py</code> <pre><code># src/reducer.py\nclass TestReducer:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    def process_result(self, result, parameters=None):\n        pass\n</code></pre></p>"},{"location":"tutorials/analysis/#replaying-captured-data","title":"Replaying captured data","text":"<p>With this in place, it is possible to replay captured data. Generally captures are provided by the staff from a generic experiment. For this tutorial, you use a specifically crafted capture <code>dump_xrd.cbors</code> which needs to downloaded to a new <code>data</code> folder.</p> <pre><code>LOG_LEVEL=\"DEBUG\" dranspose replay -w \"src.worker:TestWorker\" -r \"src.reducer:TestReducer\" -f data/dump_xrd.cbors\n</code></pre> <p>The <code>LOG_LEVEL=\"DEBUG\"</code> is the most verbose output of the replay script. It does not output anything meaningful yet.</p>"},{"location":"tutorials/analysis/#events","title":"Events","text":"<p>The first argument <code>event</code> to the worker function <code>process_event</code> is an EventData object. The worker function needs to be able to handle all kind of events.</p> <p>A first debugging step is to inspect the events and print them. A good way is to use the python logging system. Create a logger at the top of the file and then print the event to debug:</p> <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\nclass TestWorker:\n    def __init__(self, *args, **kwargs):\n        pass\n    def process_event(self, event, parameters=None):\n        logger.debug(\"event is %s\", event)\n</code></pre> <p>The output then contains:</p> <pre><code>DEBUG:src.worker:event is event_number=0 streams={'xrd': StreamData(typ='STINS', frames=[b'{\"htype\": \"header\", \"filename\": \"\", \"msg_number\": 0}'], length=1)}\nDEBUG:src.worker:event is event_number=1 streams={'xrd': StreamData(typ='STINS', frames=[b'{\"htype\": \"image\", \"frame\": 0, \"shape\": [10, 10], \"type\": \"uint16\", \"compression\": \"none\", \"msg_number\": 1}', b'\\x05\\x00\\x12\\x00\\r\\x00\\x06\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x0e\\x00\\x13\\x00\\x11\\x00\\t\\x00\\x00\\x00\\x01\\x00\\x08\\x00\\x07\\x00\\x06\\x00\\x03\\x00\\x00\\x00\\n\\x00\\x0f\\x00\\x01\\x00\\x06\\x00\\x0f\\x00\\x13\\x00\\x14\\x00\\x12\\x00\\x10\\x00\\x05\\x00\\x00\\x00\\x06\\x00\\x02\\x00\\x10\\x00\\x13\\x00\\x13\\x00\\x12\\x00\\x12\\x00\\x14\\x00\\x0f\\x00\\x02\\x00\\x00\\x00\\x05\\x00\\x13\\x00\\x11\\x00\\x0b\\x00\\n\\x00\\x0c\\x00\\x10\\x00\\x13\\x00\\x05\\x00\\x00\\x00\\x08\\x00\\x14\\x00\\x0f\\x00\\x0c\\x00\\t\\x00\\t\\x00\\x0f\\x00\\x14\\x00\\n\\x00\\x00\\x00\\x08\\x00\\x13\\x00\\x13\\x00\\x0e\\x00\\x0b\\x00\\x0c\\x00\\x11\\x00\\x11\\x00\\x05\\x00\\x05\\x00\\x02\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x10\\x00\\x13\\x00\\x14\\x00\\x0f\\x00\\x03\\x00\\x0e\\x00\\x00\\x00\\x04\\x00\\r\\x00\\x14\\x00\\x13\\x00\\x14\\x00\\x0f\\x00\\x03\\x00\\x01\\x00\\x13\\x00\\x0b\\x00\\x01\\x00\\x02\\x00\\x08\\x00\\t\\x00\\x05\\x00\\x02\\x00\\x01\\x00\\x0c\\x00'], length=2)}\n</code></pre> <p>That shows us the general structure of an event. Every event has an <code>event_number</code> (the same event may be processed by multiple workers, so it is not unique). The <code>streams</code> dictionary then contains all streams of data available in this event. The values are StreamData objects with a <code>typ</code> and the raw zmq <code>frames</code>.</p>"},{"location":"tutorials/analysis/#parse-streamdata","title":"Parse StreamData","text":"<p>As the raw zmq frames are not useful for further processing, dranspose provides parser for the default protocols. For the <code>xrd</code> example, we need the STINS <code>parse</code> function from <code>dranspose.middlewares.stream1</code>. If you import multiple parsers, it makes sense to rename them.</p> <p>Then we check for the <code>xrd</code> stream, parse it and output it.</p> <pre><code>import logging\nfrom dranspose.middlewares.stream1 import parse as parse_stins\n\nlogger = logging.getLogger(__name__)\n\nclass TestWorker:\n    def __init__(self, *args, **kwargs):\n        pass\n    def process_event(self, event, parameters=None):\n        if \"xrd\" in event.streams:\n            acq = parse_stins(event.streams[\"xrd\"])\n            logger.debug(\"acquisition is %s\", acq)\n</code></pre> <p>The debug output then shows the parsed <code>xrd</code> stream:</p> <pre><code>DEBUG:src.worker:data is msg_number=0 htype='header' filename=''\nDEBUG:src.worker:data is msg_number=1 htype='image' frame=0 shape=[10, 10] type='uint16' compression='none' data=array([[ 5, 18, 13,  6,  1,  0,  0,  6, 14, 19],\n       [17,  9,  0,  1,  8,  7,  6,  3,  0, 10],\n       [15,  1,  6, 15, 19, 20, 18, 16,  5,  0],\n       [ 6,  2, 16, 19, 19, 18, 18, 20, 15,  2],\n       [ 0,  5, 19, 17, 11, 10, 12, 16, 19,  5],\n       [ 0,  8, 20, 15, 12,  9,  9, 15, 20, 10],\n       [ 0,  8, 19, 19, 14, 11, 12, 17, 17,  5],\n       [ 5,  2, 16, 17, 18, 16, 19, 20, 15,  3],\n       [14,  0,  4, 13, 20, 19, 20, 15,  3,  1],\n       [19, 11,  1,  2,  8,  9,  5,  2,  1, 12]], dtype=uint16)\n</code></pre> <p>The STINS fields are parsed and the values are available as a numpy array in the <code>data</code> attribute.</p>"},{"location":"tutorials/analysis/#useful-map-function","title":"Useful Map function","text":"<p>The main goal of the worker (map function) is to map a large dataset to a smaller representation. As an example analysis, we are only interested in the mean intensity in a region of interest in the top right corner.</p> <p>The object returned by parse_stins depends on the position in the stream. STINS defines a start, data and end messages. Only the data messages contain a data attribute. We filter for them with the <code>isinstance</code>.</p> <pre><code>import logging\nimport numpy as np\n\nfrom dranspose.middlewares.stream1 import parse as parse_stins\nfrom dranspose.data.stream1 import Stream1Data\n\nlogger = logging.getLogger(__name__)\n\nclass TestWorker:\n    def __init__(self, *args, **kwargs):\n        pass\n    def process_event(self, event, parameters=None):\n        if \"xrd\" in event.streams:\n            acq = parse_stins(event.streams[\"xrd\"])\n            if isinstance(acq, Stream1Data):\n                intensity = np.mean(acq.data[:2,8:])\n                logger.debug(\"intensity is %f\", intensity)\n                return intensity\n</code></pre> <p>Which outputs <pre><code>DEBUG:src.worker:intensity is 9.500000\nDEBUG:src.worker:intensity is 10.500000\nDEBUG:src.worker:intensity is 11.000000\nDEBUG:src.worker:intensity is 5.500000\n</code></pre></p> <p>We assume this mean value is the essence of the event which is also small enough to pass to the reduce step.  Whatever the <code>process_event</code> event returns is passed to the reducer.</p> <p>Warning</p> <p>Not all python objects can be returned. Especially functions cannot be passed to the reducer. All results are transferred via pickle. The replay script will throw an error if your object cannot be serialized.</p>"},{"location":"tutorials/analysis/#reduce-function","title":"Reduce Function","text":"<p>The return values of the worker are passed to <code>process_result</code> function which we can output:</p> <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\nclass TestReducer:\n    def __init__(self, *args, **kwargs):\n        pass\n    def process_result(self, result, parameters=None):\n        logger.debug(\"result is %s\", result)\n</code></pre> <p>This outputs</p> <pre><code>DEBUG:src.worker:intensity is 9.500000\nDEBUG:src.reducer:result is event_number=1 worker='development0' parameters_hash='688787d8ff144c502c7f5cffaafe2cc588d86079f9de88304c26b0cb99ce91c6' payload=9.5\nDEBUG:src.worker:intensity is 10.500000\nDEBUG:src.reducer:result is event_number=2 worker='development0' parameters_hash='688787d8ff144c502c7f5cffaafe2cc588d86079f9de88304c26b0cb99ce91c6' payload=10.5\n</code></pre> <p>The ResultData has an <code>event_number</code> and a <code>payload</code>. Note that for event 0, the payload is <code>None</code> as the worker did not return anything and therefore the reducer is not called.</p> <p>Info</p> <p>Workers returning <code>None</code> on many events is a good strategy to cope with high frequency events to not overwhelm the reducer. </p>"},{"location":"tutorials/analysis/#inter-event-analysis","title":"Inter Event Analysis","text":"<p>While the workers only have access to an event at a time, the reducer gets called for all events and can e.g. calculate temporal trends. For that, a starting point is convenient. The <code>__init__</code> function is the convenient place. We are interested in the delta of the intensity between each two events.</p> <p>Opposite to initialising, the end of an experiment is useful to output the analysis a final time. <code>finish</code> is called once all results are processed.</p> <p>The output of  <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\nclass TestReducer:\n    def __init__(self, *args, **kwargs):\n        self.evolution = [0]\n        self.last_value = 0\n\n    def process_result(self, result, parameters=None):\n        if result.event_number &gt; (len(self.evolution) - 1):\n            self.evolution += [None] * (1 + result.event_number - len(self.evolution))\n        self.evolution[result.event_number] = result.payload - self.evolution\n        self.last_value = result.payload.intensity\n\n    def finish(self, parameters=None):\n        logger.info(\"delta were %s\", self.evolution)\n</code></pre></p> <p>is</p> <pre><code>INFO:src.reducer:delta were [0, 9.5, 1.0, 10.0, -4.5, 6.75, -3.75, 9.0, -1.5, 11.75]\n</code></pre> <p>The <code>process_result</code> function takes a lot of care on how to append data to the list. This function may be called with different results, coming from different workers, for the same event. Or a worker returns <code>None</code> for an event, so the <code>process_result</code> is never called for this event. Due to these possibilities, there is no guarantee on the order of the events. The code above takes care of this, by filling the list with <code>None</code> to the event received.</p>"},{"location":"tutorials/analysis/#write-results-to-file","title":"Write results to file","text":"<p>Now that we have the delta values, it is nice to save them to a file. This is best performed in the reducer. To decide where to save the data, it is nice to get the path of the raw data first. The STINS stream has a <code>filename</code> attribute in the series start message.  By convention, it might be <code>\"\"</code> (empty string) to indicate a live viewing without saving data. Your pipeline should honor this as well and only save data if a filename is set.</p> <p>The quickest way is for the worker to return a dictionary with either a <code>filename</code> key or an <code>intensity</code> key:</p> <pre><code>import logging\nimport numpy as np\n\nfrom dranspose.middlewares.stream1 import parse as parse_stins\nfrom dranspose.data.stream1 import Stream1Data, Stream1Start, Stream1End\n\nlogger = logging.getLogger(__name__)\n\nclass TestWorker:\n    def __init__(self, *args, **kwargs):\n        pass\n    def process_event(self, event, parameters=None):\n        logger.debug(event)\n        if \"xrd\" in event.streams:\n            acq = parse_stins(event.streams[\"xrd\"])\n            if isinstance(acq, Stream1Start):\n                logger.info(\"start message %s\", acq)\n                return {\"filename\": acq.filename}\n            elif isinstance(acq, Stream1Data):\n                intensity = np.mean(acq.data[:2,8:])\n                logger.debug(\"intensity is %f\", intensity)\n                return {\"intensity\": intensity}\n</code></pre> <p>The reducer then has to check which keys are present in the result and process them differently.</p> <p>With only two keys, it is easy to keep an overview, however using dictionaries to pass data quickly becomes messy. A cleaner solution is to return a dataclass depending on the intent.</p> <pre><code>import logging\nfrom dataclasses import dataclass\nimport numpy as np\n\nfrom dranspose.middlewares.stream1 import parse as parse_stins\nfrom dranspose.data.stream1 import Stream1Data, Stream1Start, Stream1End\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass Start:\n    filename: str\n\n@dataclass\nclass Result:\n    intensity: float\n\nclass TestWorker:\n    def __init__(self, *args, **kwargs):\n        pass\n    def process_event(self, event, parameters=None):\n        logger.debug(event)\n        if \"xrd\" in event.streams:\n            acq = parse_stins(event.streams[\"xrd\"])\n            if isinstance(acq, Stream1Start):\n                logger.info(\"start message %s\", acq)\n                return Start(acq.filename)\n            elif isinstance(acq, Stream1Data):\n                intensity = np.mean(acq.data[:2,8:])\n                logger.debug(\"intensity is %f\", intensity)\n                return Result(intensity)\n</code></pre> <p>The reducer is then able to separate the different event types cleanly by importing the two dataclasses and checking with <code>isinstance</code></p> <pre><code>import logging\nimport h5py\nimport numpy as np\n\nfrom .worker import Start, Result\n\nlogger = logging.getLogger(__name__)\n\nclass TestReducer:\n    def __init__(self, *args, **kwargs):\n        self.evolution = [0]\n        self.last_value = 0\n\n    def process_result(self, result, parameters=None):\n        if isinstance(result.payload, Start):\n            logger.info(\"start message\")\n        elif isinstance(result.payload, Result):\n            logger.debug(\"got result %s\", result.payload)\n            if result.event_number &gt; (len(self.evolution) - 1):\n                self.evolution += [None] * (1 + result.event_number - len(self.evolution))\n            self.evolution[result.event_number] = result.payload.intensity - self.last_value\n            self.last_value = result.payload.intensity\n</code></pre> <p>This explicitly writes out the protocol on how the workers pass data to the reducer and avoids implicit contracts which are hard for others to understand and maintain.</p> <p>Like in most trigger maps, the first packet of each stream is broadcast to all workers in the replay. This makes sense as it is normally sent before the first trigger and contains only meta information.</p> <p>This needs care when using the Start message in the reducer to open a file. The file should only be opened once, no matter how many worker messages it receives. A simple way is to set a <code>None</code> file handle in <code>__init__</code> and only open the file if it is still <code>None</code>.</p> <p>Before opening the file, the containing directory needs to be created with <code>os.makedirs</code>. For this tutorial, the sample data has a filename of <code>output/xrd.h5</code> but it is usually an absolute path. Beware that this is the filename where upstream the raw data is saved to. The analysis pipeline should write to a modified filename.</p> <p>The reducer now saves the intensity values to a <code>_processed</code> suffixed file:</p> <pre><code>import logging\nimport h5py\nimport os\nimport numpy as np\n\nfrom .worker import Start, Result\n\nlogger = logging.getLogger(__name__)\n\nclass TestReducer:\n    def __init__(self, *args, **kwargs):\n        self.evolution = [0]\n        self.last_value = 0\n        self._fh = None\n        self._dset = None\n\n    def process_result(self, result, parameters=None):\n        if isinstance(result.payload, Start):\n            logger.info(\"start message\")\n            if self._fh is None:\n                name, ext = os.path.splitext(result.payload.filename)\n                dest_filename = f\"{name}_processed{ext}\"\n                os.makedirs(os.path.dirname(dest_filename), exist_ok=True)\n                self._fh = h5py.File(dest_filename, 'w')\n                self._dset = self._fh.create_dataset(\"reduced\", (0,), maxshape=(None, ), dtype=np.float32)\n        elif isinstance(result.payload, Result):\n            logger.debug(\"got result %s\", result.payload)\n            if result.event_number &gt; (len(self.evolution) - 1):\n                self.evolution += [None] * (1 + result.event_number - len(self.evolution))\n            self.evolution[result.event_number] = result.payload.intensity - self.last_value\n            self.last_value = result.payload.intensity\n\n            oldsize = self._dset.shape[0]\n            self._dset.resize(max(1 + result.event_number, oldsize), axis=0)\n            self._dset[result.event_number] = result.payload.intensity\n\n\n    def finish(self, parameters=None):\n        logger.info(\"delta were %s\", self.evolution)\n        if self._fh is not None:\n            self._fh.close()\n</code></pre> <p>The file contains all the processed values</p> <pre><code>$ h5dump output/xrd_processed.h5\nHDF5 \"output/xrd_processed.h5\" {\nGROUP \"/\" {\n   DATASET \"reduced\" {\n      DATATYPE  H5T_IEEE_F32LE\n      DATASPACE  SIMPLE { ( 10 ) / ( H5S_UNLIMITED ) }\n      DATA {\n      (0): 0, 9.25, 11.25, 11.75, 4.25, 2.25, 3, 4.75, 7.75, 10.75\n      }\n   }\n}\n}\n</code></pre>"},{"location":"tutorials/analysis/#processing-parameters","title":"Processing Parameters","text":"<p>The current worker calulates the mean of a fixed area (<code>[:2,8:]</code>). Changing requires updating the code and pushing a new image, which is time consuming. To provide flexibility, dranspose supports parameters, which can change at any time. Though, if you change them during an active scan, you get no guarantees on when which worker gets the new paramters.</p> <p>To register parameters, the worker or reducer needs to implement a static <code>describe_parameters</code> method wich returns a list of <code>dranspose.parameters</code> instances. The paramter values, depending on their type, are available in the <code>parameters</code> dict and the <code>value</code> attribute:</p> <pre><code>import logging\nfrom dataclasses import dataclass\nimport numpy as np\n\nfrom dranspose.middlewares.stream1 import parse as parse_stins\nfrom dranspose.data.stream1 import Stream1Data, Stream1Start, Stream1End\nfrom dranspose.parameters import IntParameter\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass Start:\n    filename: str\n\n@dataclass\nclass Result:\n    intensity: float\n\nclass TestWorker:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def describe_parameters():\n        params = [\n            IntParameter(name=\"till_x\", default=2),\n            IntParameter(name=\"from_y\", default=8),\n        ]\n        return params\n\n    def process_event(self, event, parameters=None):\n        logger.debug(event)\n        if \"xrd\" in event.streams:\n            acq = parse_stins(event.streams[\"xrd\"])\n            if isinstance(acq, Stream1Start):\n                logger.info(\"start message %s\", acq)\n                return Start(acq.filename)\n            elif isinstance(acq, Stream1Data):\n                intensity = np.mean(acq.data[:parameters[\"till_x\"].value,parameters[\"from_y\"].value:])\n                logger.debug(\"intensity is %f\", intensity)\n                return Result(intensity)\n</code></pre> <p>These parameters are managed by the dranspose controller and are get/set via the REST interface. For replay testing, the parameters are provided in a json file with the value encoded as string in the <code>data</code> field:</p> <pre><code>[{\"name\": \"till_x\", \"data\": \"3\"},\n{\"name\": \"from_y\", \"data\": \"7\"}]\n</code></pre> <p>To provide the parameter file to the replay, add the <code>-p</code> argument</p> <pre><code>dranspose replay -w \"src.worker:TestWorker\" -r \"src.reducer:TestReducer\" -f data/dump_xrd.cbors -p test_params.json\n</code></pre> <p>As a good practice, it is recommended to store the parameters along with the processed data to be able to reconstruct how it was reduced. The parameters defined in the worker are also available in the reducer:</p> <pre><code>                self._fh = h5py.File(dest_filename, 'w')\n                self._dset = self._fh.create_dataset(\"reduced\", (0,), maxshape=(None, ), dtype=np.float32)\n                self._fh.create_dataset(\"till_x\", data=parameters[\"till_x\"].value)\n                self._fh.create_dataset(\"from_y\", data=parameters[\"from_y\"].value)\n</code></pre> <p>To result in a self descriptive file:</p> <pre><code>$ h5dump output/xrd_processed.h5\nHDF5 \"output/xrd_processed.h5\" {\nGROUP \"/\" {\n   DATASET \"from_y\" {\n      DATATYPE  H5T_STD_I64LE\n      DATASPACE  SCALAR\n      DATA {\n      (0): 7\n      }\n   }\n   DATASET \"reduced\" {\n      DATATYPE  H5T_IEEE_F32LE\n      DATASPACE  SIMPLE { ( 10 ) / ( H5S_UNLIMITED ) }\n      DATA {\n      (0): 0, 8.88889, 8.66667, 8.11111, 6, 6.66667, 8.22222, 10.6667,\n      (8): 12.4444, 14.3333\n      }\n   }\n   DATASET \"till_x\" {\n      DATATYPE  H5T_STD_I64LE\n      DATASPACE  SCALAR\n      DATA {\n      (0): 3\n      }\n   }\n}\n}\n</code></pre>"},{"location":"tutorials/analysis/#heavy-processing","title":"Heavy Processing","text":"<p>For some applications the mean of a small rectangle might be sufficient, but more often it is interesting to analysse the full 2d image. One option is to azimuthally integrate the image to get the intensity on a radial. An approachable packet is the <code>azint</code> conda package. After installing it, it needs the detector geometry. Intially we will provide it fully manually by creating a <code>Detector</code> and a <code>Pony</code> instance.</p> <p>After creating an <code>AzimuthalIntegrator</code> instance, we send the radial axis of q values to the reducer to save them to the h5 file and prepare the dimensions of the dataset with values, having the same length.</p> <pre><code>import logging\nfrom dataclasses import dataclass\nimport numpy as np\nimport azint\n\nfrom dranspose.middlewares.stream1 import parse as parse_stins\nfrom dranspose.data.stream1 import Stream1Data, Stream1Start, Stream1End\nfrom dranspose.parameters import IntParameter\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass Start:\n    filename: str\n    radial_axis: list[float]\n\n@dataclass\nclass Result:\n    intensity: float\n    integrated: list[float]\n\nclass TestWorker:\n    def __init__(self, *args, **kwargs):\n        pixel_size = 0.75e-6\n        det = azint.detector.Detector(pixel_size, pixel_size, (10,10))\n        poni = azint.Poni(det,  dist=30*pixel_size,\n                                poni1 = 5*pixel_size,\n                                poni2 = 5*pixel_size,\n                                rot1 = 0,\n                                rot2 = 0,\n                                rot3 = 0,\n                                wavelength = 1e-10)\n        self.ai = azint.AzimuthalIntegrator(poni,\n                                 4,\n                                 5,\n                                 unit='q',\n                                 solid_angle=True)\n\n    @staticmethod\n    def describe_parameters():\n        params = [\n            IntParameter(name=\"till_x\", default=2),\n            IntParameter(name=\"from_y\", default=8),\n        ]\n        return params\n\n    def process_event(self, event, parameters=None):\n        logger.debug(event)\n        if \"xrd\" in event.streams:\n            acq = parse_stins(event.streams[\"xrd\"])\n            if isinstance(acq, Stream1Start):\n                logger.info(\"start message %s\", acq)\n                return Start(acq.filename, self.ai.radial_axis)\n            elif isinstance(acq, Stream1Data):\n                intensity = np.mean(acq.data[:parameters[\"till_x\"].value,parameters[\"from_y\"].value:])\n                logger.debug(\"intensity is %f\", intensity)\n                I, _ = self.ai.integrate(acq.data)\n                logger.info(\"I %s %s\", I, self.ai.radial_axis)\n                return Result(intensity, I)\n</code></pre>"},{"location":"tutorials/analysis/#poni-file-sources","title":"Poni file sources","text":"<p>There are multiple options on how to provide the geometry to build the poni file. The individual float values could be exposed as parameters, however that will be invonvenient for users used to poni files. There is a <code>BinaryParameter</code> available which holds the full content of a file. The advantage is that the workers don't need filesystem access to read the poni file. However, another process needs to upload the poni file, which is normally the tango device server displaying the paramters.</p>"},{"location":"tutorials/analysis/#writing-the-diffractograms","title":"Writing the diffractograms","text":"<p>It remains to place the data calculated by the workers into the h5 file by the reducer.</p> <pre><code>import logging\nimport h5py\nimport os\nimport numpy as np\n\nfrom .worker import Start, Result\n\nlogger = logging.getLogger(__name__)\n\nclass TestReducer:\n    def __init__(self, *args, **kwargs):\n        self.evolution = [0]\n        self.last_value = 0\n        self._fh = None\n        self._dset = None\n        self._Iset = None\n\n    def process_result(self, result, parameters=None):\n        if isinstance(result.payload, Start):\n            logger.info(\"start message\")\n            if self._fh is None:\n                name, ext = os.path.splitext(result.payload.filename)\n                dest_filename = f\"{name}_processed{ext}\"\n                os.makedirs(os.path.dirname(dest_filename), exist_ok=True)\n                self._fh = h5py.File(dest_filename, 'w')\n                self._dset = self._fh.create_dataset(\"reduced\", (0,), maxshape=(None, ), dtype=np.float32)\n                self._fh.create_dataset(\"till_x\", data=parameters[\"till_x\"].value)\n                self._fh.create_dataset(\"from_y\", data=parameters[\"from_y\"].value)\n                number_qbins = len(result.payload.radial_axis)\n                self._Iset = self._fh.create_dataset(\"I\", (0, number_qbins), maxshape=(None, number_qbins), dtype=np.float32)\n                self._fh.create_dataset(\"radial_axis\", data=result.payload.radial_axis)\n        elif isinstance(result.payload, Result):\n            logger.debug(\"got result %s\", result.payload)\n            if result.event_number &gt; (len(self.evolution) - 1):\n                self.evolution += [None] * (1 + result.event_number - len(self.evolution))\n            self.evolution[result.event_number] = result.payload.intensity - self.last_value\n            self.last_value = result.payload.intensity\n\n            oldsize = self._dset.shape[0]\n            self._dset.resize(max(1 + result.event_number, oldsize), axis=0)\n            self._dset[result.event_number] = result.payload.intensity\n\n            oldsize = self._Iset.shape[0]\n            self._Iset.resize(max(1 + result.event_number, oldsize), axis=0)\n            self._Iset[result.event_number] = result.payload.integrated\n\n    def finish(self, parameters=None):\n        logger.info(\"delta were %s\", self.evolution)\n        if self._fh is not None:\n            self._fh.close()\n</code></pre>"},{"location":"tutorials/ingesters/","title":"Ingesters","text":"<p>Writing new ingesters is required for consuming new data streams.</p>"},{"location":"tutorials/viewers/","title":"Live Viewers","text":"<p>The reducer publishes data available for live viewing or to influence the scanning.</p> <p>To retrieve the data, the reducer exposes an HTTP interface which follows the hdf rest api</p> <p>This allows direct viewing with h5pyd compatible software, such as silx &gt;= 2.2.0</p> <p>Example</p> <pre><code>import h5pyd\n\nf = h5pyd.File(\"http://&lt;reducer&gt;:&lt;port&gt;/\", \"r\")\ndata = f[\"map\"][:,4:8,3]\n</code></pre> <p>sets data to the <code>publish[\"map\"][:,4:8,3]</code> element of the numpy array in \"map\" and otherwise behaves like an hdf5 file.</p>"}]}